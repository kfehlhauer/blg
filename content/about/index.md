# Resume/CV    										                                                                                                               
Kurt Fehlhauer     										                                                                                                               
email: kfehlhauer@pm.me

Summary
--------
I specialize in leading large-scale data engineering initiatives and driving enterprise-wide data architecture transformations. My efforts have enabled scalable multi-petabyte platforms that support artificial intelligence applications and data-driven decision-making across global operations. I am passionate about enabling AI usage within the teams I manage to accelerate the delivery of solutions. 

My expertise includes designing and deploying robust data platforms using technologies like Databricks Spark, Kubernetes, and Delta Lake, while advancing cost-efficient solutions such as Rust-based query engines. Committed to fostering innovation, I build global teams that deliver and empower analytics at scale.

I constantly look to increase my skillset. Currently, I am experimenting with Rust on the Solana blockchain and building WASM-powered sites using Dioxus.

Experience
--------------
2/2022 - Present
### Chief Data Architect
#### Stellantis: Remote
Spearheaded deparment-wide data architecture transformation at Stellantis, delivering scalable multi-petabyte platforms that enable AI initiatives and data-driven decision making across global operations.

- Built and led a global data engineering organization spanning multiple continents, establishing DevOps practices that reduced system delivery time by 40%
- Architected and deployed a multi-petabyte data platform using Databricks Spark, Kubernetes, and Delta Lake, supporting 500+ employees with enterprise-scale analytics
- Pioneered implementation of Rust-based query engines (DataFusion, delta-rs) to reduce query costs by 80% for data quality time series data. 
- Successfully consolidated disparate data systems from the FCA LLC and PSA Group merger, eliminating redundancies and reducing operational costs by $2M annually
- Designed and implemented petabyte-scale vehicle data collection architecture for both research and production fleets, enabling real-time analytics and predictive maintenance
- Led cross-functional collaboration with AI teams to productionize large language models (LLMs), accelerating time-to-market for AI-powered features
- Established comprehensive data governance framework and PII handling protocols, ensuring regulatory compliance across multiple regions
- Forecast yearly multimillion-dollar data platform budge
- Currently serving as Acting Head of Data Governance (March 2025), focusing on data discovery, AI enablement, and data democratization initiatives
- Developed portable cloud-agnostic architectures, ensuring business continuity in regions with limited cloud vendor availability
_____


5/2019 – 2/2022	
### Senior Manager, ETL
#### Activision Publishing: Remote
Led a data engineering team supporting the Call of Duty franchise and game studio analytics, driving platform modernization initiatives that reduced data processing times by 50% while ensuring regulatory compliance across global markets.

- Managed the analytical data pipeline architecture for the Call of Duty franchise, processing petabytes of player behavioral data and game telemetry to support 100M+ active users
- Orchestrated successful cloud migration from AWS to Google Cloud Platform, reducing infrastructure costs by 30% and improving cross-platform compatibility for development teams
- Spearheaded legacy ETL system modernization, normalizing data across multiple Call of Duty titles and achieving a 50% reduction in data availability latency
- Implemented Astronomer Airflow deployment, standardizing workflow orchestration and reducing deployment complexity
- Consolidated fragmented big data ecosystem (Qubole, Hive, Presto, Redshift) into unified Databricks platform, eliminating vendor sprawl and reducing operational overhead by 40%
- Championed MLFlow adoption across the data science organization, establishing standardized ML lifecycle management for 50+ data scientists
- Engineered a high-performance third-party data ingestion framework using functional programming paradigms (Cats/ZIO, Circe, http4s) on Kubernetes, enabling real-time integration of external market data
- Established a comprehensive data privacy and compliance framework implementing GDPR and CCPA industry regulations, ensuring zero compliance violations across global data operations
- Built scalable data transformation pipelines converting proprietary game artifacts into Spark SQL-queryable formats, democratizing data access for 200+ analysts and stakeholders
- Mentored 20+ engineers in modern data stack technologies (Airflow, Kubernetes, Scala, Spark).
- Managed $5M+ annual vendor contracts and platform investments, optimizing cost-per-query metrics and ensuring 99.9% platform availability
_____


6/2014 – 4/2019
### Lead Database Architect
#### Activision Publishing: Boulder, CO/Remote
Pioneered game analytics data architecture at Activision, establishing foundational analytics infrastructure that supported billion-dollar gaming franchises and enabled data-driven game design decisions across global development studios.

- Architected and managed a comprehensive data ecosystem for the Call of Duty franchise, processing petabytes of player telemetry and game performance data supporting 300M+ registered users
- Led groundbreaking company-wide adoption of Apache Spark and Airflow, establishing Activision as an early adopter of modern big data technologies and reducing processing times by 60%
- Designed and implemented a self-service Spark-based ETL framework adopted across Call of Duty mainline and  Call of Duty Mobile, democratizing data access for 30+ analysts
- Spearheaded platform consolidation initiative, migrating from fragmented Qubole/Hive/Presto ecosystem to unified Databricks Delta Lake architecture, reducing operational complexity by 80%
- Established Activision's first MLFlow implementation for data science workflows, standardizing machine learning lifecycle management across 20+ data scientists and accelerating model deployment by 40%
- Built custom Spark extensions and UDFs that enhanced analytical capabilities, simplifying otherwise complex and redundant SQL
- Transformed proprietary game artifact data into Spark SQL-compatible formats, enabling cross-studio analytics and reducing time-to-insight for game developers by 70%
- Modernized legacy studio data tools to integrate with enterprise big data frameworks, eliminating data silos and improving development team productivity
- Mentored cross-functional teams on big data best practices, creating technical standards that accelerated analytical insight delivery by 60%
_____


1/2013 – 6/2014
### Senior Consultant
#### FICO: Remote
Enhanced credit and retail applications for diverse financial institutions and implemented recommendation systems for major pharmaceutical companies, utilizing Python, Vertica, and Pentaho.

Delivered mission-critical marketing and Voice/SMS gateway systems for Fortune 500 clients, utilizing Python, Vertica, and Pentaho. 
- Rescued and delivered a voice/SMS gateway system for the nation's largest bank after inheriting a year-long stalled project, preserving $10M+ annual client relationship and preventing potential contract termination of other services.
- Designed and implemented recommendation engines for major pharmaceutical companies, optimizing drug treatment awareness by 15%
- Modernized Kia Motors' dealer optimization platform, migrating legacy VB.Net/PostgreSQL architecture to high-performance Java/Vertica solution, improving query response times by 80%
- Designed scalable ETL frameworks using Pentaho Data Integration, processing terabytes of marketing data and reducing data pipeline failures by 60%
- Mentored 15+ developers in advanced ETL techniques and data processing methodologies
- Contributed to talent acquisition strategy, interviewing and recommending candidates that strengthened technical capabilities across multiple client engagement teams
_____


10/2011 – 12/2012
### Senior ETL Architect
#### Productive Data Solutions: Denver, CO
Provided strategic guidance and expert knowledge that implemented ETL solutions for multiple states to power their healthcare exchanges.

- Designed and implemented a hybrid ETL architecture combining Pentaho Data Integration with Python automation, processing millions of records daily and reducing data processing errors by 40%
- Drastically improved deployment processes by architecting a file-based Pentaho repository system with Subversion integration, achieving 99% deployment time reduction (from 60+ minutes to 30 seconds)
- Developed a HIPAA-compliant healthcare reporting system using Python, ensuring zero privacy violations while enabling real-time analytics for patient records
- Enhanced development team productivity by 50% through Agile methodology optimization, collaborating with business analysts to refine user story definitions and sprint planning processes
- Established automated testing framework using Linux shell scripting, mentoring QA teams on DevOps practices that reduced manual testing efforts by 70%
- Led technical training initiatives for development teams on advanced Python ETL techniques, improving code quality and standardizing best practices across projects
- Contributed to strategic hiring decisions through technical interviewing of SQL developers, ensuring team capability alignment with client needs
- Delivered solutions for complex data integration challenges across healthcare, financial services, and retail verticals under tight regulatory constraints
Led the design and implementation of effective ETL systems for clients, providing strategic guidance and expert knowledge.
_____

3/2006 – 10/2011
### Software Architect
#### Transzap: Denver, CO
Drove enterprise software architecture transformation at high-growth oil and gas fintech startup, delivering scalable e-payables solutions that contributed to the company's recognition in Deloitte Fast 500 and supported millions in transaction processing volume.

- Pioneered adoption of Python-based automation framework, reducing manual data processing time by 80% and establishing foundation for scalable ETL operations across enterprise systems
- Architected and executed critical legacy system migration from Orion to Tomcat application server, ensuring zero-downtime transition for customer-facing e-payables platform serving thousands of active users
- Introduced cutting-edge columnar database technology (Vertica) to the enterprise stack, offloading analytical workloads from transactional systems and improving query performance by 90%
- Led SSAS cube modernization initiative, migrating complex MDX-based analytics to SQL-accessible Vertica platform, democratizing data access for business analysts
- Built a comprehensive ETL infrastructure using Pentaho Data Integration, processing financial transactions daily while maintaining 99.9% data accuracy
- Engineered SQL Server Integration Services pipelines for enterprise data warehouse, enabling real-time business intelligence for executive decision-making
- Optimized mission-critical C# application (Spendworks) startup performance, achieving a 95% reduction in load times (from minutes to seconds), dramatically improving user adoption rates
- Designed scalable system architecture supporting the company's rapid growth trajectory, handling increases in transaction volume without performance degradation
- Mentored development team on emerging technologies and architectural best practices, establishing technical standards that supported company scaling from startup to enterprise
_____


7/2000 – 3/2006
### Application Architect
#### Calpine: Fort Collins, CO
Led enterprise architecture at Fortune 500 energy company, pioneering real-time power plant analytics and telemetry systems that optimized operations across a fleet of natural gas facilities while driving company recognition as InformationWeek Top 100 Innovator.

- Spearheaded architectural oversight for $10M+ portfolio of mission-critical development projects, ensuring technical excellence across enterprise systems
- Pioneered early adoption of Microsoft .NET technologies at enterprise scale, collaborating directly with Microsoft development teams on C# language evolution and establishing Calpine as an industry technology leader
- Directly contributed technical innovations that earned Calpine a 5th place ranking in InformationWeek Top 100 Innovators (2005), positioning the company as an energy sector technology pioneer
- Managed project budgets up to $600K and established PMO standards for timeline management, delivering 95% of projects on time and under budget across the IT portfolio
- Architected a comprehensive business intelligence platform using ASP.NET, SQL Server, and SSAS, enabling real-time analysis of natural gas and electric power sales data
- Built enterprise data warehouse integrating Maximo inventory systems using SQL Server, C#, and DTS, automating critical operational reporting and reducing manual processes by 80%
- Developed custom data mapping platform using C#, ADO.NET, Oracle, and OSI PI, standardizing data integration across heterogeneous industrial control systems
- Enhanced custom OLAP caching server, optimizing performance for complex energy market calculations (gas days, peaking periods, off-peak analysis) with sub-second response times
- Enhanced legacy C++/MFC libraries to support dynamic contract period management, improving operational flexibility for diverse power purchase agreements
_____


12/1999 – 7/2000
### Systems Analyst II
#### City of Thornton: Thornton, CO
Led municipal technology modernization initiatives for a growing suburban city, implementing mission-critical systems serving 77K+ residents while establishing software development best practices and mentoring technical staff on emerging enterprise technologies.

- Architected and implemented a comprehensive software development lifecycle (SDLC) framework for municipal IT projects, reducing project delivery times by 30% and establishing quality standards across city departments
- Provided technical leadership and mentorship to MIS staff on advanced programming technologies, including C++, COM, MTS, and ASP, elevating team capabilities in enterprise application development
- Led strategic technology procurement processes, evaluating and recommending software solutions for critical municipal operations, including public safety, utilities, and citizen services systems
- Modernized legacy municipal systems serving police, fire, utilities, and administrative departments, ensuring 99.9% uptime for citizen-facing services and emergency response systems
- Spearheaded technical hiring initiatives, conducting candidate evaluations and building development team capabilities to support the city's rapid growth and technology advancement needs
- Collaborated with department heads to align technology solutions with operational requirements, ensuring seamless integration across police dispatch, utilities management, and citizen services platforms
- Created technical documentation, creating a sustainable IT operations framework for the City of Thornton
_____


1/1999 – 12/1999
### Information Technology Lead
#### VantagePoint Network: Fort Collins, CO
Led software engineering that pioneered the development of a groundbreaking precision agriculture platform, creating one of the industry's first web-based agricultural technology solutions that enabled crop professionals to optimize yields while reducing environmental impact across thousands of farming operations.

- Architected revolutionary GPS-based yield mapping system using C++, ATL COM, ADO, MTS, MSMQ, and Oracle technologies, enabling real-time precision agriculture data collection that improved crop yields by 15-20% for early adopters
- Designed a comprehensive soil analysis and management platform integrating C++ ATL COM objects with enterprise Oracle databases, providing farmers with data-driven insights for optimized fertilizer application and soil health monitoring
- Built an advanced geospatial data migration engine using ESRI SDE APIs and C++, enabling seamless integration of precision agriculture data across heterogeneous farming systems and GIS platforms
- Created a web-based crop record management system using ASP and Oracle, digitizing paper-based processes and reducing administrative overhead by 60% for agricultural operations
- Led quality assurance standardization initiative, collaborating with QA teams to establish bug tracking, testing protocols, and code quality standards that reduced production defects by 40%
- Partnered with database architects to design a scalable agricultural data warehouse supporting complex crop rotation analysis, field mapping, and yield prediction algorithms
- Facilitated code review processes and mentored development team on emerging web technologies, establishing engineering best practices that supported the company's rapid growth in the AgTech market
- Contributed to technical innovations that positioned VantagePoint as an early leader in the precision agriculture technology sector
_____


2/1995 – 1/1999
### Programmer/Analyst
#### State Farm Insurance Companies: Bloomington, IL
Delivered enterprise-scale insurance technology solutions for a Fortune 50 company, architecting mission-critical systems that processed millions of policies annually while mentoring development teams and establishing coding standards across business units.

- Architected a comprehensive COM-based integration framework connecting third-party insurance software with State Farm's mainframe legacy systems, enabling seamless data flow across enterprise applications serving 80M+ policyholders
- Built pioneering intranet-based policy rating application using COM, COM TI, DB2, DHTML, and MTS technologies, reducing policy quote generation time from hours to minutes and improving agent productivity by 40%
- Led after-hours technical training initiatives in C++ programming, developing internal expertise
- Designed high-performance data replication system using C++, DB2, and MQ Series, synchronizing marketing data across 5,000+ agent locations nationwide with 99.9% reliability
- Provided critical vendor support in debugging a complex MFC C++ life insurance illustration application, ensuring accurate actuarial calculations for a multi-billion dollar life insurance portfolio
- Enhanced AionDS-based expert system for auto policy pricing, implementing advanced business rules that improved pricing accuracy by 25% and reduced underwriting exceptions
- Optimized legacy COBOL applications supporting core insurance operations, achieving 60% performance improvements through systematic tuning and debugging initiatives
- Collaborated with business analysts to translate complex insurance regulations into automated business rules, enabling consistent policy management across all product lines
- Contributed to digital transformation initiatives that positioned State Farm as a technology leader in the insurance industry during the early web adoption period
_____


1/1996 - 12/1996
### C++ Instructor
#### Heartland Community College: Bloomington, IL
Delivered comprehensive object-oriented programming education to 50+ students while maintaining a full-time State Farm position, developing curriculum and teaching methodologies that achieved a 95% student success rate in C++ programming concepts.

- Designed and delivered a comprehensive C++ curriculum covering advanced object-oriented programming principles, data structures, and software engineering best practices for computer science and engineering students
- Taught complex programming concepts, including inheritance, polymorphism, exception handling, and operator overloading, to a diverse student population with varying technical backgrounds
- Developed hands-on laboratory exercises and real-world programming projects that improved student comprehension by 40% compared to traditional lecture-only approaches
- Mentored students in software design principles, debugging techniques, and industry-standard coding practices, preparing them for internships and entry-level development positions
- Created teaching materials and practical assignments that bridged academic concepts with industry applications, drawing from my development experience
- Collaborated with computer science department faculty to align curriculum with industry needs and emerging programming trends
- Maintained 95% student retention rate through engaging instruction methods and individualized support for struggling learners
- Applied State Farm enterprise development experience to provide students with practical insights into the commercial software development lifecycle
_____


5/1993 – 1/1995
### Computer Operator
#### Rockwell Automation Allen – Bradley: Mequon, WI
Operated mission-critical mainframe systems for Fortune 500 industrial automation leader while contributing to successful ISO 9000 certification initiatives.

- Operated and maintained enterprise mainframe systems processing critical manufacturing data for Rockwell's worldwide industrial automation operations, supporting $2B+ annual revenue
- Developed advanced JCL and REXX automation scripts that reduced manual backup processes by 75% and eliminated human error in critical data protection workflows
- Led automation initiative for mainframe application scheduling, designing workflows that increased operational efficiency and reduced after-hours support requirements
- Supported multiple successful ISO 9000 quality certification audits through meticulous documentation of mainframe operational procedures, ensuring compliance with international manufacturing standards
- Collaborated with systems analysts and programmers on troubleshooting complex system issues
- Demonstrated exceptional attention to detail in system documentation and change management
- Provided technical support during system upgrades and maintenance windows, coordinating with engineering teams to minimize production disruption
- Built foundational expertise in enterprise system operations and quality management that supported transition into a software engineering career

			
Education
-----------
University of Wisconsin - Milwaukee  
Bachelor of Business Administration (Completed in December 1994)  
Major: Management Information Systems  
