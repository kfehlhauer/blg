# Resume/CV    										                                                                                                               
Kurt Fehlhauer     										                                                                                                               
email: kfehlhauer@pm.me

Summary
--------
A hands-on engineering leader with a proven track record of creating teams that transform visions into systems.  

Experience
--------------
2/2022 - Present
### Chief Data Architect
#### Stellantis: Remote
Spearheaded the creation and currently manages the data platform team, encompassing data, DevOps, and software engineers. Key focus includes overseeing all vehicle telemetry data for distinguished Stellantis brands, such as Maserati and Ram trucks, and collaborating with partners to deliver robust data products at an enterprise scale.

Key Accomplishments and Responsibilities:
- Set the strategic roadmap and vision for enterprise-scale data engineering utilizing Databricks Spark and Delta Lake
- Created a 20-plus data engineering and DevOps organization
- Orchestrated the consolidation of legacy data systems from two distinct car companies: FCA LLC and PSA Group
- Constructed a multi-petabyte data platform leveraging Airflow, Kubernetes, and Spark
- Pioneered the introduction of Spark streaming to process billions of daily records
- Forecasted and managed a multimillion-dollar data platform budget
- Successfully migrated data from various on-premise data sources to the cloud
- Regularly report on status and progress directly to C-suite leadership
- Champion IT innovation to enhance data accessibility and utility through thoughtful design and technology choices
- Partnered with data privacy officers to implement effective anonymization strategies, protecting personally identifiable information (PII)
- Established infrastructure supporting machine learning to enrich the vehicle cockpit experience
- Continuously exploring technologies like Rust to improve system performance, lower costs, and environmental impact
- Cultivated a robust engineering culture committed to continuous learning and skill expansion
- Collaborated with partners to foster innovations in engineering and marketing
_____


5/2019 – 2/2022	
### Senior Manager, ETL
#### Activision Publishing: Remote
Led an international team of data engineers. Developed data products, extended support to data scientists and analytics analysts across the company, and collaborated with data scientists to execute feature engineering.

Key Contributions and Responsibilities:
- Managed comprehensive silver/gold level data for the Call of Duty franchise
- Led a successful migration of ETL processes from Amazon Web Services (AWS) to Google Cloud Platform (GCP), enhancing platform compatibility
- Developed a Spark-based ETL framework that empowered self-service ETL for many use cases
- Migrated and normalized a legacy ETL system to streamline various Call of Duty title data, achieving a 50% reduction in data availability wait time
- Introduced Astronomer Airflow to ease the deployment of Airflow across various data teams at Activision
- Consolidated and simplified Activision's big data platforms from Qubole/Hive/Presto and Redshift to Databricks
- Promoted the adoption of MLFlow for data science workflows within the Activision Data Science community
- Enhanced Spark functionality through user-defined functions and integrated third-party data with Activision's game data for improved insights
- Developed a third-party data ingestion framework using Cats/ZIO, Circe, and http4s on Kubernetes
- Implemented GDPR, CCPA, and other privacy measures within the data lake to ensure compliance with data protection regulations
- Partnered with Activision game studios to convert game artifact data into formats queryable in SparkSQL, retooling small data tools to function within Activision's big data frameworks
- Improved Diversity, Equity, and Inclusion (DEI) efforts by widening the hiring pipeline for potential candidates
- Mentored staff in Airflow, Kubernetes, Scala, and Spark, enhancing team capabilities
- Managed multimillion-dollar contracts, ensuring efficient utilization of resources and delivery of various data products
_____


6/2014 – 4/2019
### Lead Database Architect
#### Activision Publishing: Boulder, CO/Remote
Championed significant advancements in Activision's analytics, model-building capabilities, and game design support. Innovated by introducing the use of Apache Airflow and Spark company-wide, significantly impacting the organization's data management and analytical capabilities.

Key Contributions and Responsibilities:
- Collaborating with game developers to optimize gameplay elements such as vehicles and weapons in Call of Duty: Black Ops IV through data-driven analytics
- Collaborated with data scientists to construct models that enhanced gameplay performance
- Boosted the Play of The Match (PTOM) simulation's performance by 20%
- Pioneered the introduction and training of Apache Spark at Activision, enabling more efficient data analysis
- Developed Spark extensions in Scala to handle encoded data
- Managed the hiring process for data engineers and data scientists, contributing to a highly skilled team
- Spearheaded the company-wide adoption of Airflow and its migration from DCOS to Kubernetes
- Oversaw multiple Hive, Presto, and Spark clusters within Qubole
- Formulated best practices for utilizing big data technologies such as Presto and Apache Spark
- Established a data pipeline service for capturing prelaunch and beta data for Call of Duty titles
- Designed ETL processes using Python Pandas dataframes for data ingestion for the Chinese version of Call of Duty
- Worked closely with Tencent to meet the data needs for Call of Duty Online
- Implemented a Vertica columnar database to support data from Call of Duty Online
_____


1/2013 – 6/2014
### Senior Consultant
#### FICO: Remote
Enhanced credit and retail applications for diverse financial institutions and implemented recommendation systems for major pharmaceutical companies, utilizing Python, Vertica, and Pentaho.

Key Contributions and Responsibilities:
- Led a team that preserved FICO's relationship with the nation's largest bank, significantly contributing to client retention
- Successfully implemented a credit card fraud application, overcoming a year-long delay by another team and demonstrating problem-solving skills and technical proficiency
- Designed and implemented ETL processes using Pentaho Data Integration, improving data flow and quality
- Transitioned Kia's application for identifying the optimal dealer and service dealer from VB.Net and PostgreSQL to Java and Vertica, enhancing system performance and reliability
- Mentored developers in employing Python for diverse ETL techniques, fostering a culture of continuous learning and development
- Participated in the hiring process, recommending staff for recruitment to strengthen the team
_____


10/2011 – 12/2012
### Senior ETL Architect
#### Productive Data Solutions: Denver, CO
Led the design and implementation of effective ETL systems for clients, providing strategic guidance and expert knowledge.

Key Contributions and Responsibilities:
- Designed and implemented ETL processes utilizing a blend of Pentaho Data Integration and Python, improving data workflow and integration
- Developed a unique data mapping solution using Django, JQuery, and Oracle, enabling a smooth migration to databases with different source and target schemas
- Recommended and facilitated the transition of a client's Pentaho repository to a file-based system via subversion, dramatically reducing deployment time from over an hour to a mere 30 seconds
- Educated developers on diverse ETL techniques utilizing Python, contributing to team skill development
- Implemented a HIPPA-compliant reporting system using Python, enhancing data security and privacy
- Mentored QA staff on automation strategies through Linux shell scripting, promoting a culture of continuous learning and innovation
- Enhanced sprint velocity by 50% by leading an initiative to refine user stories for ETL sprints in collaboration with business analysts and clients
- Participated in the hiring process, conducting interviews for SQL developers
_____

3/2006 – 10/2011
### Software Architect
#### Transzap: Denver, CO
Instrumental in enhancing the performance of both customer-facing software products and internal data systems.

Key Contributions and Responsibilities:
- Pioneered the introduction of Python for efficient data transformations and task automation
- Developed multiple Python applications to ensure system conversion and upgrade integrity
- Led the migration of Transzap's legacy e-payables system from Orion to Tomcat
- Introduced columnar database technology (Vertica) to offload reporting load from the transactional database, optimizing performance
- Converted SSAS cubes to Vertica, simplifying data access via SQL instead of MDX
- Crafted Java web services for performing analytical queries against Vertica, returning results as XMLA
- Implemented several ETL systems using Pentaho Data Integration, enhancing data management processes
- Contributed to system design and implementation that led to Transzap's recognition in the Deloitte Fast 500
- Developed SQL Server Integration Services to streamline data migration into a data warehouse
- Reduced the start-up time of Tranzap’s Spendwork's C# application from minutes to seconds, significantly improving user experience
_____


7/2000 – 3/2006
### Application Architect
#### Calpine: Fort Collins, CO
Established standards and best practices for data warehousing, XML, web services, and service-oriented architecture (SOA). Also, built systems to facilitate the performance and efficiency monitoring of Calpine's power plant fleet.

Key Contributions and Responsibilities:
- Provided architectural oversight to numerous development projects, ensuring optimal technical solutions
- Played a key role in Calpine's early adoption of Microsoft's .Net technologies, collaborating directly with Microsoft on the C# language
- Directly contributed to Calpine's 5th place ranking in the InformationWeek Top 100 Innovators (InformationWeek, Sept. 19, 2005 issue)
- Budgeted projects and set initial project management timelines for projects up to $600K, demonstrating financial acumen
- Conducted comprehensive reviews of database designs for new systems or enhancements to existing systems
- Evaluated business intelligence tools, gaining consensus from all information services organizations within Calpine
- Developed a data warehousing and OLAP application using ASP.Net, SQL Server, SSAS for comparing meter data for natural gas and electric power sales
- Designed and implemented an OLAP cube for power plant fleet reliability analysis
- Created a data warehouse to automate reporting from a Maximo inventory system using SQL Server, C#, and DTS
- Designed, developed, and tested back-end components for real-time nationwide telemetry gathering from power plants
- Created a data mapping tool using C#, ADO.NET, Oracle, and OSI PI
- Designed and developed the database maintaining power plant meta-data for the Calpine fleet
- Modified C++/MFC-based libraries to accommodate varying contract periods for power plants
- Designed, developed, and created an OLAP server from scratch that cached different periods such as gas days, peaking periods, and off-peak periods
- Participated in the hiring process, interviewing and recommending software development candidates
_____


12/1999 – 7/2000
### Systems Analyst II
#### City of Thornton: Thornton, CO
Guided MIS staff utilizing advanced programming languages and technologies, including C++, COM, MTS, and ASP. Also, implemented, maintained, and upgraded mission-critical systems for the City of Thornton.

Key Contributions and Responsibilities:
- Participated in the hiring process, conducting interviews and recommending software development candidates
- Provided expert advice on software purchases and implemented a development life cycle for internal projects, supporting effective project management
- Provided technical support and maintenance for various systems utilized by the City of Thornton, ensuring seamless operations
- Continually improved system performance, reliability, and security through regular system upgrades and updates, enhancing organizational efficiency
_____


1/1999 – 12/1999
### Information Technology Lead
#### VantagePoint Network: Fort Collins, CO
Was a key contributor to creating one of the first web-based agricultural platforms, aiding crop professionals in increasing crop yields while reducing costs and environmental impact.

Key Contributions and Responsibilities:
- Designed and built an innovative system for collecting GPS-based yield card information, leveraging technologies such as C++, ATL COM, ADO, MTS, MSMQ, Oracle, and SDE
- Created a system for storing soil test information, demonstrating expertise in utilizing C++ ATL COM objects with ADO, MTS, Oracle, and SDE
- Implemented a COM object to migrate spatial data in an ESRI SDE Oracle database using C++, ATL COM, and the SDE API, enhancing data management efficiency
- Built an NT Service with a COM interface to encrypt user id and password information, enhancing system security
- Designed and implemented a web-based crop record management system using ASP, ADO, and Oracle, improving record-keeping efficiency
- Streamlined the deployment process between development, test, and production systems by creating installation programs with Wise, VBScript, and MTS package exports
- Assisted the QA department in developing guidelines for bug reporting, testing, and correction, improving software quality
- Collaborated with database designers to create a well-structured crop database system
- Organized and participated in code review sessions, ensuring high-quality, efficient code
_____


2/1995 – 1/1999
### Programmer/Analyst
#### State Farm Insurance Companies: Bloomington, IL
Played a critical role in designing and implementing mission-critical business systems for various insurance products.

Key Contributions and Responsibilities:
- Designed and built COM objects, integrating third-party insurance software packages with State Farm's legacy systems, enhancing compatibility and efficiency
- Created an intranet-based application for online policy rating, leveraging technologies such as COM, COM TI, DB2, DHTML, and MTS, improving user experience and policy management
- Established coding standards for my area, serving as a mentor and resource for analysts in C/C++ and MFC, contributing to improved code quality and team expertise
- Educated and mentored employees in C++ during after-hours sessions, enhancing team skills and knowledge
- Developed a system to replicate marketing data for up to 5000 locations using C++, DB2, and MQ Series, enabling efficient data management and access
- Debugged a third-party MFC C++ application for life insurance illustrations at the vendor's site, ensuring accurate and reliable system performance
- Enhanced an expert system written in AionDS for pricing auto policies, improving pricing accuracy and policy management
- Performed tuning and debugging of COBOL applications, ensuring optimal performance and reliability.
- Collaborated with business analysts to uncover business rules for expert systems, enhancing system functionality and relevance 
_____


1/1996 - 12/1996
### C++ Instructor
#### Heartland Community College: Bloomington, IL
Leveraged expertise in C++ programming to educate students on the language's fundamentals and the principles of object-oriented programming.

The comprehensive curriculum focused on the following:
- Understanding and applying analysis and design principles
- Mastering the creation of classes and objects
- Implementing effective exception-handling techniques
- Exploring the concepts of inheritance and polymorphism
- Applying overloaded operators and understanding their applications
- Adhering to best practices in C++ programming
_____


5/1993 – 1/1995
### Computer Operator
#### Rockwell Automation Allen – Bradley: Mequon, WI
Played integral in maintaining and operating mainframe, network, and PC systems. Also, collaborated closely with systems analysts and system programmers to ensure the smooth running of operations.

Key Contributions and Responsibilities:
- Supported several successful ISO 9000 audits by diligently maintaining documentation for procedures related to mainframe operations
- Demonstrated advanced skills in writing JCL and REXX scripts, which were utilized to run programs and conduct backups efficiently
- Regularly monitored and provided reports on telecommunication usage and availability to optimize system performance
- Played a critical role in the successful implementation of automated scheduling for mainframe applications, contributing significantly to increased efficiency and reliability

			
Education
-----------
University of Wisconsin - Milwaukee  
Bachelor of Business Administration (Completed in December 1994)  
Major: Management Information Systems  
