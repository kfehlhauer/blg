<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Kurt Fehlhauer</title><meta name=keywords content><meta name=description content="Resume/CV Kurt Fehlhauer email: kfehlhauer@pm.me
Summary A hands-on engineering leader with a proven track record of creating teams that transform visions into systems.
Experience 2/2022 - Present
Chief Data Architect Stellantis: Remote Spearheaded the creation and currently manages the data platform team, encompassing data, DevOps, and software engineers. Key focus includes overseeing all vehicle telemetry data for distinguished Stellantis brands, such as Maserati and Ram trucks, and collaborating with partners to deliver robust data products at an enterprise scale."><meta name=author content><link rel=canonical href=https://kurtfehlhauer.com/about/><link crossorigin=anonymous href=/assets/css/stylesheet.bccfefac377bc340f06c260aed1bddf49a4354816d7c570d6aac75a997986c95.css integrity="sha256-vM/vrDd7w0DwbCYK7Rvd9JpDVIFtfFcNaqx1qZeYbJU=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://kurtfehlhauer.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://kurtfehlhauer.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://kurtfehlhauer.com/favicon-32x32.png><link rel=apple-touch-icon href=https://kurtfehlhauer.com/apple-touch-icon.png><link rel=mask-icon href=https://kurtfehlhauer.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content><meta property="og:description" content="Resume/CV Kurt Fehlhauer email: kfehlhauer@pm.me
Summary A hands-on engineering leader with a proven track record of creating teams that transform visions into systems.
Experience 2/2022 - Present
Chief Data Architect Stellantis: Remote Spearheaded the creation and currently manages the data platform team, encompassing data, DevOps, and software engineers. Key focus includes overseeing all vehicle telemetry data for distinguished Stellantis brands, such as Maserati and Ram trucks, and collaborating with partners to deliver robust data products at an enterprise scale."><meta property="og:type" content="article"><meta property="og:url" content="https://kurtfehlhauer.com/about/"><meta property="article:section" content><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="Resume/CV Kurt Fehlhauer email: kfehlhauer@pm.me
Summary A hands-on engineering leader with a proven track record of creating teams that transform visions into systems.
Experience 2/2022 - Present
Chief Data Architect Stellantis: Remote Spearheaded the creation and currently manages the data platform team, encompassing data, DevOps, and software engineers. Key focus includes overseeing all vehicle telemetry data for distinguished Stellantis brands, such as Maserati and Ram trucks, and collaborating with partners to deliver robust data products at an enterprise scale."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"","item":"https://kurtfehlhauer.com/about/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"","name":"","description":"Resume/CV Kurt Fehlhauer email: kfehlhauer@pm.me\nSummary A hands-on engineering leader with a proven track record of creating teams that transform visions into systems.\nExperience 2/2022 - Present\nChief Data Architect Stellantis: Remote Spearheaded the creation and currently manages the data platform team, encompassing data, DevOps, and software engineers. Key focus includes overseeing all vehicle telemetry data for distinguished Stellantis brands, such as Maserati and Ram trucks, and collaborating with partners to deliver robust data products at an enterprise scale.","keywords":[],"articleBody":"Resume/CV Kurt Fehlhauer email: kfehlhauer@pm.me\nSummary A hands-on engineering leader with a proven track record of creating teams that transform visions into systems.\nExperience 2/2022 - Present\nChief Data Architect Stellantis: Remote Spearheaded the creation and currently manages the data platform team, encompassing data, DevOps, and software engineers. Key focus includes overseeing all vehicle telemetry data for distinguished Stellantis brands, such as Maserati and Ram trucks, and collaborating with partners to deliver robust data products at an enterprise scale.\nKey Accomplishments and Responsibilities:\n Set the strategic roadmap and vision for enterprise-scale data engineering utilizing Databricks Spark and Delta Lake Created a 20-plus data engineering and DevOps organization Orchestrated the consolidation of legacy data systems from two distinct car companies: FCA LLC and PSA Group Constructed a multi-petabyte data platform leveraging Airflow, Kubernetes, and Spark Pioneered the introduction of Spark streaming to process billions of daily records Forecasted and managed a multimillion-dollar data platform budget Successfully migrated data from various on-premise data sources to the cloud Regularly report on status and progress directly to C-suite leadership Champion IT innovation to enhance data accessibility and utility through thoughtful design and technology choices Partnered with data privacy officers to implement effective anonymization strategies, protecting personally identifiable information (PII) Established infrastructure supporting machine learning to enrich the vehicle cockpit experience Continuously exploring technologies like Rust to improve system performance, lower costs, and environmental impact Cultivated a robust engineering culture committed to continuous learning and skill expansion Collaborated with partners to foster innovations in engineering and marketing   5/2019 – 2/2022\nSenior Manager, ETL Activision Publishing: Remote Led an international team of data engineers. Developed data products, extended support to data scientists and analytics analysts across the company, and collaborated with data scientists to execute feature engineering.\nKey Contributions and Responsibilities:\n Managed comprehensive silver/gold level data for the Call of Duty franchise Led a successful migration of ETL processes from Amazon Web Services (AWS) to Google Cloud Platform (GCP), enhancing platform compatibility Developed a Spark-based ETL framework that empowered self-service ETL for many use cases Migrated and normalized a legacy ETL system to streamline various Call of Duty title data, achieving a 50% reduction in data availability wait time Introduced Astronomer Airflow to ease the deployment of Airflow across various data teams at Activision Consolidated and simplified Activision’s big data platforms from Qubole/Hive/Presto and Redshift to Databricks Promoted the adoption of MLFlow for data science workflows within the Activision Data Science community Enhanced Spark functionality through user-defined functions and integrated third-party data with Activision’s game data for improved insights Developed a third-party data ingestion framework using Cats/ZIO, Circe, and http4s on Kubernetes Implemented GDPR, CCPA, and other privacy measures within the data lake to ensure compliance with data protection regulations Partnered with Activision game studios to convert game artifact data into formats queryable in SparkSQL, retooling small data tools to function within Activision’s big data frameworks Improved Diversity, Equity, and Inclusion (DEI) efforts by widening the hiring pipeline for potential candidates Mentored staff in Airflow, Kubernetes, Scala, and Spark, enhancing team capabilities Managed multimillion-dollar contracts, ensuring efficient utilization of resources and delivery of various data products   6/2014 – 4/2019\nLead Database Architect Activision Publishing: Boulder, CO/Remote Championed significant advancements in Activision’s analytics, model-building capabilities, and game design support. Innovated by introducing the use of Apache Airflow and Spark company-wide, significantly impacting the organization’s data management and analytical capabilities.\nKey Contributions and Responsibilities:\n Collaborating with game developers to optimize gameplay elements such as vehicles and weapons in Call of Duty: Black Ops IV through data-driven analytics Collaborated with data scientists to construct models that enhanced gameplay performance Boosted the Play of The Match (PTOM) simulation’s performance by 20% Pioneered the introduction and training of Apache Spark at Activision, enabling more efficient data analysis Developed Spark extensions in Scala to handle encoded data Managed the hiring process for data engineers and data scientists, contributing to a highly skilled team Spearheaded the company-wide adoption of Airflow and its migration from DCOS to Kubernetes Oversaw multiple Hive, Presto, and Spark clusters within Qubole Formulated best practices for utilizing big data technologies such as Presto and Apache Spark Established a data pipeline service for capturing prelaunch and beta data for Call of Duty titles Designed ETL processes using Python Pandas dataframes for data ingestion for the Chinese version of Call of Duty Worked closely with Tencent to meet the data needs for Call of Duty Online Implemented a Vertica columnar database to support data from Call of Duty Online   1/2013 – 6/2014\nSenior Consultant FICO: Remote Enhanced credit and retail applications for diverse financial institutions and implemented recommendation systems for major pharmaceutical companies, utilizing Python, Vertica, and Pentaho.\nKey Contributions and Responsibilities:\n Led a team that preserved FICO’s relationship with the nation’s largest bank, significantly contributing to client retention Successfully implemented a credit card fraud application, overcoming a year-long delay by another team and demonstrating problem-solving skills and technical proficiency Designed and implemented ETL processes using Pentaho Data Integration, improving data flow and quality Transitioned Kia’s application for identifying the optimal dealer and service dealer from VB.Net and PostgreSQL to Java and Vertica, enhancing system performance and reliability Mentored developers in employing Python for diverse ETL techniques, fostering a culture of continuous learning and development Participated in the hiring process, recommending staff for recruitment to strengthen the team   10/2011 – 12/2012\nSenior ETL Architect Productive Data Solutions: Denver, CO Led the design and implementation of effective ETL systems for clients, providing strategic guidance and expert knowledge.\nKey Contributions and Responsibilities:\n Designed and implemented ETL processes utilizing a blend of Pentaho Data Integration and Python, improving data workflow and integration Developed a unique data mapping solution using Django, JQuery, and Oracle, enabling a smooth migration to databases with different source and target schemas Recommended and facilitated the transition of a client’s Pentaho repository to a file-based system via subversion, dramatically reducing deployment time from over an hour to a mere 30 seconds Educated developers on diverse ETL techniques utilizing Python, contributing to team skill development Implemented a HIPPA-compliant reporting system using Python, enhancing data security and privacy Mentored QA staff on automation strategies through Linux shell scripting, promoting a culture of continuous learning and innovation Enhanced sprint velocity by 50% by leading an initiative to refine user stories for ETL sprints in collaboration with business analysts and clients Participated in the hiring process, conducting interviews for SQL developers   3/2006 – 10/2011\nSoftware Architect Transzap: Denver, CO Instrumental in enhancing the performance of both customer-facing software products and internal data systems.\nKey Contributions and Responsibilities:\n Pioneered the introduction of Python for efficient data transformations and task automation Developed multiple Python applications to ensure system conversion and upgrade integrity Led the migration of Transzap’s legacy e-payables system from Orion to Tomcat Introduced columnar database technology (Vertica) to offload reporting load from the transactional database, optimizing performance Converted SSAS cubes to Vertica, simplifying data access via SQL instead of MDX Crafted Java web services for performing analytical queries against Vertica, returning results as XMLA Implemented several ETL systems using Pentaho Data Integration, enhancing data management processes Contributed to system design and implementation that led to Transzap’s recognition in the Deloitte Fast 500 Developed SQL Server Integration Services to streamline data migration into a data warehouse Reduced the start-up time of Tranzap’s Spendwork’s C# application from minutes to seconds, significantly improving user experience   7/2000 – 3/2006\nApplication Architect Calpine: Fort Collins, CO Established standards and best practices for data warehousing, XML, web services, and service-oriented architecture (SOA). Also, built systems to facilitate the performance and efficiency monitoring of Calpine’s power plant fleet.\nKey Contributions and Responsibilities:\n Provided architectural oversight to numerous development projects, ensuring optimal technical solutions Played a key role in Calpine’s early adoption of Microsoft’s .Net technologies, collaborating directly with Microsoft on the C# language Directly contributed to Calpine’s 5th place ranking in the InformationWeek Top 100 Innovators (InformationWeek, Sept. 19, 2005 issue) Budgeted projects and set initial project management timelines for projects up to $600K, demonstrating financial acumen Conducted comprehensive reviews of database designs for new systems or enhancements to existing systems Evaluated business intelligence tools, gaining consensus from all information services organizations within Calpine Developed a data warehousing and OLAP application using ASP.Net, SQL Server, SSAS for comparing meter data for natural gas and electric power sales Designed and implemented an OLAP cube for power plant fleet reliability analysis Created a data warehouse to automate reporting from a Maximo inventory system using SQL Server, C#, and DTS Designed, developed, and tested back-end components for real-time nationwide telemetry gathering from power plants Created a data mapping tool using C#, ADO.NET, Oracle, and OSI PI Designed and developed the database maintaining power plant meta-data for the Calpine fleet Modified C++/MFC-based libraries to accommodate varying contract periods for power plants Designed, developed, and created an OLAP server from scratch that cached different periods such as gas days, peaking periods, and off-peak periods Participated in the hiring process, interviewing and recommending software development candidates   12/1999 – 7/2000\nSystems Analyst II City of Thornton: Thornton, CO Guided MIS staff utilizing advanced programming languages and technologies, including C++, COM, MTS, and ASP. Also, implemented, maintained, and upgraded mission-critical systems for the City of Thornton.\nKey Contributions and Responsibilities:\n Participated in the hiring process, conducting interviews and recommending software development candidates Provided expert advice on software purchases and implemented a development life cycle for internal projects, supporting effective project management Provided technical support and maintenance for various systems utilized by the City of Thornton, ensuring seamless operations Continually improved system performance, reliability, and security through regular system upgrades and updates, enhancing organizational efficiency   1/1999 – 12/1999\nInformation Technology Lead VantagePoint Network: Fort Collins, CO Was a key contributor to creating one of the first web-based agricultural platforms, aiding crop professionals in increasing crop yields while reducing costs and environmental impact.\nKey Contributions and Responsibilities:\n Designed and built an innovative system for collecting GPS-based yield card information, leveraging technologies such as C++, ATL COM, ADO, MTS, MSMQ, Oracle, and SDE Created a system for storing soil test information, demonstrating expertise in utilizing C++ ATL COM objects with ADO, MTS, Oracle, and SDE Implemented a COM object to migrate spatial data in an ESRI SDE Oracle database using C++, ATL COM, and the SDE API, enhancing data management efficiency Built an NT Service with a COM interface to encrypt user id and password information, enhancing system security Designed and implemented a web-based crop record management system using ASP, ADO, and Oracle, improving record-keeping efficiency Streamlined the deployment process between development, test, and production systems by creating installation programs with Wise, VBScript, and MTS package exports Assisted the QA department in developing guidelines for bug reporting, testing, and correction, improving software quality Collaborated with database designers to create a well-structured crop database system Organized and participated in code review sessions, ensuring high-quality, efficient code   2/1995 – 1/1999\nProgrammer/Analyst State Farm Insurance Companies: Bloomington, IL Played a critical role in designing and implementing mission-critical business systems for various insurance products.\nKey Contributions and Responsibilities:\n Designed and built COM objects, integrating third-party insurance software packages with State Farm’s legacy systems, enhancing compatibility and efficiency Created an intranet-based application for online policy rating, leveraging technologies such as COM, COM TI, DB2, DHTML, and MTS, improving user experience and policy management Established coding standards for my area, serving as a mentor and resource for analysts in C/C++ and MFC, contributing to improved code quality and team expertise Educated and mentored employees in C++ during after-hours sessions, enhancing team skills and knowledge Developed a system to replicate marketing data for up to 5000 locations using C++, DB2, and MQ Series, enabling efficient data management and access Debugged a third-party MFC C++ application for life insurance illustrations at the vendor’s site, ensuring accurate and reliable system performance Enhanced an expert system written in AionDS for pricing auto policies, improving pricing accuracy and policy management Performed tuning and debugging of COBOL applications, ensuring optimal performance and reliability. Collaborated with business analysts to uncover business rules for expert systems, enhancing system functionality and relevance    1/1996 - 12/1996\nC++ Instructor Heartland Community College: Bloomington, IL Leveraged expertise in C++ programming to educate students on the language’s fundamentals and the principles of object-oriented programming.\nThe comprehensive curriculum focused on the following:\n Understanding and applying analysis and design principles Mastering the creation of classes and objects Implementing effective exception-handling techniques Exploring the concepts of inheritance and polymorphism Applying overloaded operators and understanding their applications Adhering to best practices in C++ programming   5/1993 – 1/1995\nComputer Operator Rockwell Automation Allen – Bradley: Mequon, WI Played integral in maintaining and operating mainframe, network, and PC systems. Also, collaborated closely with systems analysts and system programmers to ensure the smooth running of operations.\nKey Contributions and Responsibilities:\n Supported several successful ISO 9000 audits by diligently maintaining documentation for procedures related to mainframe operations Demonstrated advanced skills in writing JCL and REXX scripts, which were utilized to run programs and conduct backups efficiently Regularly monitored and provided reports on telecommunication usage and availability to optimize system performance Played a critical role in the successful implementation of automated scheduling for mainframe applications, contributing significantly to increased efficiency and reliability  Education University of Wisconsin - Milwaukee\nBachelor of Business Administration (Completed in December 1994)\nMajor: Management Information Systems\n","wordCount":"2219","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://kurtfehlhauer.com/about/"},"publisher":{"@type":"Organization","name":"Kurt Fehlhauer","logo":{"@type":"ImageObject","url":"https://kurtfehlhauer.com/favicon.ico"}}}</script></head><body class=dark id=top><header class=header><nav class=nav><div class=logo><a href=https://kurtfehlhauer.com/ accesskey=h title="Kurt Fehlhauer (Alt + H)">Kurt Fehlhauer</a><div class=logo-switches></div></div><ul id=menu><li><a href=https://kurtfehlhauer.com/photography/ title=Photography><span>Photography</span></a></li><li><a href=https://kurtfehlhauer.com/posts/ title=posts><span>posts</span></a></li><li><a href=https://kurtfehlhauer.com/about/ title=About><span class=active>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://kurtfehlhauer.com/>Home</a></div><h1 class=post-title></h1><div class=post-meta></div></header><div class=post-content><h1 id=resumecv>Resume/CV<a hidden class=anchor aria-hidden=true href=#resumecv>#</a></h1><p>Kurt Fehlhauer<br>email: <a href=mailto:kfehlhauer@pm.me>kfehlhauer@pm.me</a></p><h2 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h2><p>A hands-on engineering leader with a proven track record of creating teams that transform visions into systems.</p><h2 id=experience>Experience<a hidden class=anchor aria-hidden=true href=#experience>#</a></h2><p>2/2022 - Present</p><h3 id=chief-data-architect>Chief Data Architect<a hidden class=anchor aria-hidden=true href=#chief-data-architect>#</a></h3><h4 id=stellantis-remote>Stellantis: Remote<a hidden class=anchor aria-hidden=true href=#stellantis-remote>#</a></h4><p>Spearheaded the creation and currently manages the data platform team, encompassing data, DevOps, and software engineers. Key focus includes overseeing all vehicle telemetry data for distinguished Stellantis brands, such as Maserati and Ram trucks, and collaborating with partners to deliver robust data products at an enterprise scale.</p><p>Key Accomplishments and Responsibilities:</p><ul><li>Set the strategic roadmap and vision for enterprise-scale data engineering utilizing Databricks Spark and Delta Lake</li><li>Created a 20-plus data engineering and DevOps organization</li><li>Orchestrated the consolidation of legacy data systems from two distinct car companies: FCA LLC and PSA Group</li><li>Constructed a multi-petabyte data platform leveraging Airflow, Kubernetes, and Spark</li><li>Pioneered the introduction of Spark streaming to process billions of daily records</li><li>Forecasted and managed a multimillion-dollar data platform budget</li><li>Successfully migrated data from various on-premise data sources to the cloud</li><li>Regularly report on status and progress directly to C-suite leadership</li><li>Champion IT innovation to enhance data accessibility and utility through thoughtful design and technology choices</li><li>Partnered with data privacy officers to implement effective anonymization strategies, protecting personally identifiable information (PII)</li><li>Established infrastructure supporting machine learning to enrich the vehicle cockpit experience</li><li>Continuously exploring technologies like Rust to improve system performance, lower costs, and environmental impact</li><li>Cultivated a robust engineering culture committed to continuous learning and skill expansion</li><li>Collaborated with partners to foster innovations in engineering and marketing</li></ul><hr><p>5/2019 – 2/2022</p><h3 id=senior-manager-etl>Senior Manager, ETL<a hidden class=anchor aria-hidden=true href=#senior-manager-etl>#</a></h3><h4 id=activision-publishing-remote>Activision Publishing: Remote<a hidden class=anchor aria-hidden=true href=#activision-publishing-remote>#</a></h4><p>Led an international team of data engineers. Developed data products, extended support to data scientists and analytics analysts across the company, and collaborated with data scientists to execute feature engineering.</p><p>Key Contributions and Responsibilities:</p><ul><li>Managed comprehensive silver/gold level data for the Call of Duty franchise</li><li>Led a successful migration of ETL processes from Amazon Web Services (AWS) to Google Cloud Platform (GCP), enhancing platform compatibility</li><li>Developed a Spark-based ETL framework that empowered self-service ETL for many use cases</li><li>Migrated and normalized a legacy ETL system to streamline various Call of Duty title data, achieving a 50% reduction in data availability wait time</li><li>Introduced Astronomer Airflow to ease the deployment of Airflow across various data teams at Activision</li><li>Consolidated and simplified Activision&rsquo;s big data platforms from Qubole/Hive/Presto and Redshift to Databricks</li><li>Promoted the adoption of MLFlow for data science workflows within the Activision Data Science community</li><li>Enhanced Spark functionality through user-defined functions and integrated third-party data with Activision&rsquo;s game data for improved insights</li><li>Developed a third-party data ingestion framework using Cats/ZIO, Circe, and http4s on Kubernetes</li><li>Implemented GDPR, CCPA, and other privacy measures within the data lake to ensure compliance with data protection regulations</li><li>Partnered with Activision game studios to convert game artifact data into formats queryable in SparkSQL, retooling small data tools to function within Activision&rsquo;s big data frameworks</li><li>Improved Diversity, Equity, and Inclusion (DEI) efforts by widening the hiring pipeline for potential candidates</li><li>Mentored staff in Airflow, Kubernetes, Scala, and Spark, enhancing team capabilities</li><li>Managed multimillion-dollar contracts, ensuring efficient utilization of resources and delivery of various data products</li></ul><hr><p>6/2014 – 4/2019</p><h3 id=lead-database-architect>Lead Database Architect<a hidden class=anchor aria-hidden=true href=#lead-database-architect>#</a></h3><h4 id=activision-publishing-boulder-coremote>Activision Publishing: Boulder, CO/Remote<a hidden class=anchor aria-hidden=true href=#activision-publishing-boulder-coremote>#</a></h4><p>Championed significant advancements in Activision&rsquo;s analytics, model-building capabilities, and game design support. Innovated by introducing the use of Apache Airflow and Spark company-wide, significantly impacting the organization&rsquo;s data management and analytical capabilities.</p><p>Key Contributions and Responsibilities:</p><ul><li>Collaborating with game developers to optimize gameplay elements such as vehicles and weapons in Call of Duty: Black Ops IV through data-driven analytics</li><li>Collaborated with data scientists to construct models that enhanced gameplay performance</li><li>Boosted the Play of The Match (PTOM) simulation&rsquo;s performance by 20%</li><li>Pioneered the introduction and training of Apache Spark at Activision, enabling more efficient data analysis</li><li>Developed Spark extensions in Scala to handle encoded data</li><li>Managed the hiring process for data engineers and data scientists, contributing to a highly skilled team</li><li>Spearheaded the company-wide adoption of Airflow and its migration from DCOS to Kubernetes</li><li>Oversaw multiple Hive, Presto, and Spark clusters within Qubole</li><li>Formulated best practices for utilizing big data technologies such as Presto and Apache Spark</li><li>Established a data pipeline service for capturing prelaunch and beta data for Call of Duty titles</li><li>Designed ETL processes using Python Pandas dataframes for data ingestion for the Chinese version of Call of Duty</li><li>Worked closely with Tencent to meet the data needs for Call of Duty Online</li><li>Implemented a Vertica columnar database to support data from Call of Duty Online</li></ul><hr><p>1/2013 – 6/2014</p><h3 id=senior-consultant>Senior Consultant<a hidden class=anchor aria-hidden=true href=#senior-consultant>#</a></h3><h4 id=fico-remote>FICO: Remote<a hidden class=anchor aria-hidden=true href=#fico-remote>#</a></h4><p>Enhanced credit and retail applications for diverse financial institutions and implemented recommendation systems for major pharmaceutical companies, utilizing Python, Vertica, and Pentaho.</p><p>Key Contributions and Responsibilities:</p><ul><li>Led a team that preserved FICO&rsquo;s relationship with the nation&rsquo;s largest bank, significantly contributing to client retention</li><li>Successfully implemented a credit card fraud application, overcoming a year-long delay by another team and demonstrating problem-solving skills and technical proficiency</li><li>Designed and implemented ETL processes using Pentaho Data Integration, improving data flow and quality</li><li>Transitioned Kia&rsquo;s application for identifying the optimal dealer and service dealer from VB.Net and PostgreSQL to Java and Vertica, enhancing system performance and reliability</li><li>Mentored developers in employing Python for diverse ETL techniques, fostering a culture of continuous learning and development</li><li>Participated in the hiring process, recommending staff for recruitment to strengthen the team</li></ul><hr><p>10/2011 – 12/2012</p><h3 id=senior-etl-architect>Senior ETL Architect<a hidden class=anchor aria-hidden=true href=#senior-etl-architect>#</a></h3><h4 id=productive-data-solutions-denver-co>Productive Data Solutions: Denver, CO<a hidden class=anchor aria-hidden=true href=#productive-data-solutions-denver-co>#</a></h4><p>Led the design and implementation of effective ETL systems for clients, providing strategic guidance and expert knowledge.</p><p>Key Contributions and Responsibilities:</p><ul><li>Designed and implemented ETL processes utilizing a blend of Pentaho Data Integration and Python, improving data workflow and integration</li><li>Developed a unique data mapping solution using Django, JQuery, and Oracle, enabling a smooth migration to databases with different source and target schemas</li><li>Recommended and facilitated the transition of a client&rsquo;s Pentaho repository to a file-based system via subversion, dramatically reducing deployment time from over an hour to a mere 30 seconds</li><li>Educated developers on diverse ETL techniques utilizing Python, contributing to team skill development</li><li>Implemented a HIPPA-compliant reporting system using Python, enhancing data security and privacy</li><li>Mentored QA staff on automation strategies through Linux shell scripting, promoting a culture of continuous learning and innovation</li><li>Enhanced sprint velocity by 50% by leading an initiative to refine user stories for ETL sprints in collaboration with business analysts and clients</li><li>Participated in the hiring process, conducting interviews for SQL developers</li></ul><hr><p>3/2006 – 10/2011</p><h3 id=software-architect>Software Architect<a hidden class=anchor aria-hidden=true href=#software-architect>#</a></h3><h4 id=transzap-denver-co>Transzap: Denver, CO<a hidden class=anchor aria-hidden=true href=#transzap-denver-co>#</a></h4><p>Instrumental in enhancing the performance of both customer-facing software products and internal data systems.</p><p>Key Contributions and Responsibilities:</p><ul><li>Pioneered the introduction of Python for efficient data transformations and task automation</li><li>Developed multiple Python applications to ensure system conversion and upgrade integrity</li><li>Led the migration of Transzap&rsquo;s legacy e-payables system from Orion to Tomcat</li><li>Introduced columnar database technology (Vertica) to offload reporting load from the transactional database, optimizing performance</li><li>Converted SSAS cubes to Vertica, simplifying data access via SQL instead of MDX</li><li>Crafted Java web services for performing analytical queries against Vertica, returning results as XMLA</li><li>Implemented several ETL systems using Pentaho Data Integration, enhancing data management processes</li><li>Contributed to system design and implementation that led to Transzap&rsquo;s recognition in the Deloitte Fast 500</li><li>Developed SQL Server Integration Services to streamline data migration into a data warehouse</li><li>Reduced the start-up time of Tranzap’s Spendwork&rsquo;s C# application from minutes to seconds, significantly improving user experience</li></ul><hr><p>7/2000 – 3/2006</p><h3 id=application-architect>Application Architect<a hidden class=anchor aria-hidden=true href=#application-architect>#</a></h3><h4 id=calpine-fort-collins-co>Calpine: Fort Collins, CO<a hidden class=anchor aria-hidden=true href=#calpine-fort-collins-co>#</a></h4><p>Established standards and best practices for data warehousing, XML, web services, and service-oriented architecture (SOA). Also, built systems to facilitate the performance and efficiency monitoring of Calpine&rsquo;s power plant fleet.</p><p>Key Contributions and Responsibilities:</p><ul><li>Provided architectural oversight to numerous development projects, ensuring optimal technical solutions</li><li>Played a key role in Calpine&rsquo;s early adoption of Microsoft&rsquo;s .Net technologies, collaborating directly with Microsoft on the C# language</li><li>Directly contributed to Calpine&rsquo;s 5th place ranking in the InformationWeek Top 100 Innovators (InformationWeek, Sept. 19, 2005 issue)</li><li>Budgeted projects and set initial project management timelines for projects up to $600K, demonstrating financial acumen</li><li>Conducted comprehensive reviews of database designs for new systems or enhancements to existing systems</li><li>Evaluated business intelligence tools, gaining consensus from all information services organizations within Calpine</li><li>Developed a data warehousing and OLAP application using ASP.Net, SQL Server, SSAS for comparing meter data for natural gas and electric power sales</li><li>Designed and implemented an OLAP cube for power plant fleet reliability analysis</li><li>Created a data warehouse to automate reporting from a Maximo inventory system using SQL Server, C#, and DTS</li><li>Designed, developed, and tested back-end components for real-time nationwide telemetry gathering from power plants</li><li>Created a data mapping tool using C#, ADO.NET, Oracle, and OSI PI</li><li>Designed and developed the database maintaining power plant meta-data for the Calpine fleet</li><li>Modified C++/MFC-based libraries to accommodate varying contract periods for power plants</li><li>Designed, developed, and created an OLAP server from scratch that cached different periods such as gas days, peaking periods, and off-peak periods</li><li>Participated in the hiring process, interviewing and recommending software development candidates</li></ul><hr><p>12/1999 – 7/2000</p><h3 id=systems-analyst-ii>Systems Analyst II<a hidden class=anchor aria-hidden=true href=#systems-analyst-ii>#</a></h3><h4 id=city-of-thornton-thornton-co>City of Thornton: Thornton, CO<a hidden class=anchor aria-hidden=true href=#city-of-thornton-thornton-co>#</a></h4><p>Guided MIS staff utilizing advanced programming languages and technologies, including C++, COM, MTS, and ASP. Also, implemented, maintained, and upgraded mission-critical systems for the City of Thornton.</p><p>Key Contributions and Responsibilities:</p><ul><li>Participated in the hiring process, conducting interviews and recommending software development candidates</li><li>Provided expert advice on software purchases and implemented a development life cycle for internal projects, supporting effective project management</li><li>Provided technical support and maintenance for various systems utilized by the City of Thornton, ensuring seamless operations</li><li>Continually improved system performance, reliability, and security through regular system upgrades and updates, enhancing organizational efficiency</li></ul><hr><p>1/1999 – 12/1999</p><h3 id=information-technology-lead>Information Technology Lead<a hidden class=anchor aria-hidden=true href=#information-technology-lead>#</a></h3><h4 id=vantagepoint-network-fort-collins-co>VantagePoint Network: Fort Collins, CO<a hidden class=anchor aria-hidden=true href=#vantagepoint-network-fort-collins-co>#</a></h4><p>Was a key contributor to creating one of the first web-based agricultural platforms, aiding crop professionals in increasing crop yields while reducing costs and environmental impact.</p><p>Key Contributions and Responsibilities:</p><ul><li>Designed and built an innovative system for collecting GPS-based yield card information, leveraging technologies such as C++, ATL COM, ADO, MTS, MSMQ, Oracle, and SDE</li><li>Created a system for storing soil test information, demonstrating expertise in utilizing C++ ATL COM objects with ADO, MTS, Oracle, and SDE</li><li>Implemented a COM object to migrate spatial data in an ESRI SDE Oracle database using C++, ATL COM, and the SDE API, enhancing data management efficiency</li><li>Built an NT Service with a COM interface to encrypt user id and password information, enhancing system security</li><li>Designed and implemented a web-based crop record management system using ASP, ADO, and Oracle, improving record-keeping efficiency</li><li>Streamlined the deployment process between development, test, and production systems by creating installation programs with Wise, VBScript, and MTS package exports</li><li>Assisted the QA department in developing guidelines for bug reporting, testing, and correction, improving software quality</li><li>Collaborated with database designers to create a well-structured crop database system</li><li>Organized and participated in code review sessions, ensuring high-quality, efficient code</li></ul><hr><p>2/1995 – 1/1999</p><h3 id=programmeranalyst>Programmer/Analyst<a hidden class=anchor aria-hidden=true href=#programmeranalyst>#</a></h3><h4 id=state-farm-insurance-companies-bloomington-il>State Farm Insurance Companies: Bloomington, IL<a hidden class=anchor aria-hidden=true href=#state-farm-insurance-companies-bloomington-il>#</a></h4><p>Played a critical role in designing and implementing mission-critical business systems for various insurance products.</p><p>Key Contributions and Responsibilities:</p><ul><li>Designed and built COM objects, integrating third-party insurance software packages with State Farm&rsquo;s legacy systems, enhancing compatibility and efficiency</li><li>Created an intranet-based application for online policy rating, leveraging technologies such as COM, COM TI, DB2, DHTML, and MTS, improving user experience and policy management</li><li>Established coding standards for my area, serving as a mentor and resource for analysts in C/C++ and MFC, contributing to improved code quality and team expertise</li><li>Educated and mentored employees in C++ during after-hours sessions, enhancing team skills and knowledge</li><li>Developed a system to replicate marketing data for up to 5000 locations using C++, DB2, and MQ Series, enabling efficient data management and access</li><li>Debugged a third-party MFC C++ application for life insurance illustrations at the vendor&rsquo;s site, ensuring accurate and reliable system performance</li><li>Enhanced an expert system written in AionDS for pricing auto policies, improving pricing accuracy and policy management</li><li>Performed tuning and debugging of COBOL applications, ensuring optimal performance and reliability.</li><li>Collaborated with business analysts to uncover business rules for expert systems, enhancing system functionality and relevance </li></ul><hr><p>1/1996 - 12/1996</p><h3 id=c-instructor>C++ Instructor<a hidden class=anchor aria-hidden=true href=#c-instructor>#</a></h3><h4 id=heartland-community-college-bloomington-il>Heartland Community College: Bloomington, IL<a hidden class=anchor aria-hidden=true href=#heartland-community-college-bloomington-il>#</a></h4><p>Leveraged expertise in C++ programming to educate students on the language&rsquo;s fundamentals and the principles of object-oriented programming.</p><p>The comprehensive curriculum focused on the following:</p><ul><li>Understanding and applying analysis and design principles</li><li>Mastering the creation of classes and objects</li><li>Implementing effective exception-handling techniques</li><li>Exploring the concepts of inheritance and polymorphism</li><li>Applying overloaded operators and understanding their applications</li><li>Adhering to best practices in C++ programming</li></ul><hr><p>5/1993 – 1/1995</p><h3 id=computer-operator>Computer Operator<a hidden class=anchor aria-hidden=true href=#computer-operator>#</a></h3><h4 id=rockwell-automation-allen--bradley-mequon-wi>Rockwell Automation Allen – Bradley: Mequon, WI<a hidden class=anchor aria-hidden=true href=#rockwell-automation-allen--bradley-mequon-wi>#</a></h4><p>Played integral in maintaining and operating mainframe, network, and PC systems. Also, collaborated closely with systems analysts and system programmers to ensure the smooth running of operations.</p><p>Key Contributions and Responsibilities:</p><ul><li>Supported several successful ISO 9000 audits by diligently maintaining documentation for procedures related to mainframe operations</li><li>Demonstrated advanced skills in writing JCL and REXX scripts, which were utilized to run programs and conduct backups efficiently</li><li>Regularly monitored and provided reports on telecommunication usage and availability to optimize system performance</li><li>Played a critical role in the successful implementation of automated scheduling for mainframe applications, contributing significantly to increased efficiency and reliability</li></ul><h2 id=education>Education<a hidden class=anchor aria-hidden=true href=#education>#</a></h2><p>University of Wisconsin - Milwaukee<br>Bachelor of Business Administration (Completed in December 1994)<br>Major: Management Information Systems</p></div><footer class=post-footer><ul class=post-tags></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share  on twitter" href="https://twitter.com/intent/tweet/?text=&url=https%3a%2f%2fkurtfehlhauer.com%2fabout%2f&hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share  on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fkurtfehlhauer.com%2fabout%2f&title=&summary=&source=https%3a%2f%2fkurtfehlhauer.com%2fabout%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share  on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fkurtfehlhauer.com%2fabout%2f&title="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share  on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fkurtfehlhauer.com%2fabout%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share  on whatsapp" href="https://api.whatsapp.com/send?text=%20-%20https%3a%2f%2fkurtfehlhauer.com%2fabout%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share  on telegram" href="https://telegram.me/share/url?text=&url=https%3a%2f%2fkurtfehlhauer.com%2fabout%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://kurtfehlhauer.com/>Kurt Fehlhauer</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerHTML="copy";function s(){e.innerHTML="copied!",setTimeout(()=>{e.innerHTML="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>