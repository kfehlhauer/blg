<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Kurt Fehlhauer</title><meta name=keywords content><meta name=description content="Resume/CV
Kurt Fehlhauer     										                                                                                                            
email: kfehlhauer@pm.me
Summary
I specialize in leading large-scale data engineering initiatives and driving enterprise-wide data architecture transformations. My efforts have enabled scalable multi-petabyte platforms that support artificial intelligence applications and data-driven decision-making across global operations. I am passionate about enabling AI usage within the teams I manage to accelerate the delivery of solutions.
My expertise includes designing and deploying robust data platforms using technologies such as Databricks Spark, Kubernetes, and Delta Lake, while advancing cost-efficient solutions, including Rust-based query engines. Committed to fostering innovation, I build global teams that deliver and empower analytics at scale."><meta name=author content><link rel=canonical href=https://kurtfehlhauer.com/about/><link crossorigin=anonymous href=/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css integrity="sha256-IhHKMWS+eDACT2qtKzouUghDpk+PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as=style><link rel=icon href=https://kurtfehlhauer.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://kurtfehlhauer.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://kurtfehlhauer.com/favicon-32x32.png><link rel=apple-touch-icon href=https://kurtfehlhauer.com/apple-touch-icon.png><link rel=mask-icon href=https://kurtfehlhauer.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://kurtfehlhauer.com/about/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:url" content="https://kurtfehlhauer.com/about/"><meta property="og:site_name" content="Kurt Fehlhauer"><meta property="og:title" content="Kurt Fehlhauer"><meta property="og:description" content="Resume/CV Kurt Fehlhauer email: kfehlhauer@pm.me
Summary I specialize in leading large-scale data engineering initiatives and driving enterprise-wide data architecture transformations. My efforts have enabled scalable multi-petabyte platforms that support artificial intelligence applications and data-driven decision-making across global operations. I am passionate about enabling AI usage within the teams I manage to accelerate the delivery of solutions.
My expertise includes designing and deploying robust data platforms using technologies such as Databricks Spark, Kubernetes, and Delta Lake, while advancing cost-efficient solutions, including Rust-based query engines. Committed to fostering innovation, I build global teams that deliver and empower analytics at scale."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="Resume/CV
Kurt Fehlhauer     										                                                                                                            
email: kfehlhauer@pm.me
Summary
I specialize in leading large-scale data engineering initiatives and driving enterprise-wide data architecture transformations. My efforts have enabled scalable multi-petabyte platforms that support artificial intelligence applications and data-driven decision-making across global operations. I am passionate about enabling AI usage within the teams I manage to accelerate the delivery of solutions.
My expertise includes designing and deploying robust data platforms using technologies such as Databricks Spark, Kubernetes, and Delta Lake, while advancing cost-efficient solutions, including Rust-based query engines. Committed to fostering innovation, I build global teams that deliver and empower analytics at scale."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"","item":"https://kurtfehlhauer.com/about/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"","name":"","description":"Resume/CV Kurt Fehlhauer email: kfehlhauer@pm.me\nSummary I specialize in leading large-scale data engineering initiatives and driving enterprise-wide data architecture transformations. My efforts have enabled scalable multi-petabyte platforms that support artificial intelligence applications and data-driven decision-making across global operations. I am passionate about enabling AI usage within the teams I manage to accelerate the delivery of solutions.\nMy expertise includes designing and deploying robust data platforms using technologies such as Databricks Spark, Kubernetes, and Delta Lake, while advancing cost-efficient solutions, including Rust-based query engines. Committed to fostering innovation, I build global teams that deliver and empower analytics at scale.\n","keywords":[],"articleBody":"Resume/CV Kurt Fehlhauer email: kfehlhauer@pm.me\nSummary I specialize in leading large-scale data engineering initiatives and driving enterprise-wide data architecture transformations. My efforts have enabled scalable multi-petabyte platforms that support artificial intelligence applications and data-driven decision-making across global operations. I am passionate about enabling AI usage within the teams I manage to accelerate the delivery of solutions.\nMy expertise includes designing and deploying robust data platforms using technologies such as Databricks Spark, Kubernetes, and Delta Lake, while advancing cost-efficient solutions, including Rust-based query engines. Committed to fostering innovation, I build global teams that deliver and empower analytics at scale.\nI continually strive to expand my skill set. Currently, I am experimenting with Rust on the Solana blockchain and building WASM-powered sites using Dioxus.\nExperience 2/2022 - Present\nChief Data Architect Stellantis: Remote Spearheaded department-wide data architecture transformation at Stellantis, delivering scalable multi-petabyte platforms that enable AI initiatives and data-driven decision making across global operations.\nBuilt and led a global data engineering organization spanning multiple continents, establishing DevOps practices that reduced system delivery time by 40% Architected and deployed a multi-petabyte data platform using Databricks Spark, Kubernetes, and Delta Lake, supporting 500+ employees with enterprise-scale analytics Pioneered implementation of Rust-based query engines (DataFusion, delta-rs) to reduce query costs by 80% for data quality time series data. Successfully consolidated disparate data systems from the FCA LLC and PSA Group merger, eliminating redundancies and reducing operational costs by $2M annually Designed and implemented petabyte-scale vehicle data collection architecture for both research and production fleets, enabling real-time analytics and predictive maintenance Led cross-functional collaboration with AI teams to productionize large language models (LLMs), accelerating time-to-market for AI-powered features Established comprehensive data governance framework and PII handling protocols, ensuring regulatory compliance across multiple regions Forecast yearly multimillion-dollar data platform budget Currently serving as Acting Head of Data Governance (March 2025), focusing on data discovery, AI enablement, and data democratization initiatives Developed portable cloud-agnostic architectures, ensuring business continuity in regions with limited cloud vendor availability 5/2019 â€“ 2/2022\nSenior Manager, ETL Activision Publishing: Remote Led a data engineering team supporting the Call of Duty franchise and game studio analytics, driving platform modernization initiatives that reduced data processing times by 50% while ensuring regulatory compliance across global markets.\nManaged the analytical data pipeline architecture for the Call of Duty franchise, processing petabytes of player behavioral data and game telemetry to support 100M+ active users Orchestrated successful cloud migration from AWS to Google Cloud Platform, reducing infrastructure costs by 30% and improving cross-platform compatibility for development teams Spearheaded legacy ETL system modernization, normalizing data across multiple Call of Duty titles and achieving a 50% reduction in data availability latency Implemented Astronomer Airflow deployment, standardizing workflow orchestration and reducing deployment complexity Consolidated fragmented big data ecosystem (Qubole, Hive, Presto, Redshift) into unified Databricks platform, eliminating vendor sprawl and reducing operational overhead by 40% Championed MLFlow adoption across the data science organization, establishing standardized ML lifecycle management for 50+ data scientists Engineered a high-performance third-party data ingestion framework using functional programming paradigms (Cats/ZIO, Circe, http4s) on Kubernetes, enabling real-time integration of external market data Established a comprehensive data privacy and compliance framework implementing GDPR and CCPA industry regulations, ensuring zero compliance violations across global data operations Built scalable data transformation pipelines converting proprietary game artifacts into Spark SQL-queryable formats, democratizing data access for 200+ analysts and stakeholders Mentored 20+ engineers in modern data stack technologies (Airflow, Kubernetes, Scala, Spark). Managed $5M+ annual vendor contracts and platform investments, optimizing cost-per-query metrics and ensuring 99.9% platform availability 6/2014 â€“ 4/2019\nLead Database Architect Activision Publishing: Boulder, CO/Remote Pioneered game analytics data architecture at Activision, establishing foundational analytics infrastructure that supported billion-dollar gaming franchises and enabled data-driven game design decisions across global development studios.\nArchitected and managed a comprehensive data ecosystem for the Call of Duty franchise, processing petabytes of player telemetry and game performance data supporting 300M+ registered users Led groundbreaking company-wide adoption of Apache Spark and Airflow, establishing Activision as an early adopter of modern big data technologies and reducing processing times by 60% Designed and implemented a self-service Spark-based ETL framework adopted across Call of Duty mainline and Call of Duty Mobile, democratizing data access for 30+ analysts Spearheaded platform consolidation initiative, migrating from fragmented Qubole/Hive/Presto ecosystem to unified Databricks Delta Lake architecture, reducing operational complexity by 80% Established Activisionâ€™s first MLFlow implementation for data science workflows, standardizing machine learning lifecycle management across 20+ data scientists and accelerating model deployment by 40% Built custom Spark extensions and UDFs that enhanced analytical capabilities, simplifying otherwise complex and redundant SQL Transformed proprietary game artifact data into Spark SQL-compatible formats, enabling cross-studio analytics and reducing time-to-insight for game developers by 70% Modernized legacy studio data tools to integrate with enterprise big data frameworks, eliminating data silos and improving development team productivity Mentored cross-functional teams on big data best practices, creating technical standards that accelerated analytical insight delivery by 60% 1/2013 â€“ 6/2014\nSenior Consultant FICO: Remote Enhanced credit and retail applications for diverse financial institutions and implemented recommendation systems for major pharmaceutical companies, utilizing Python, Vertica, and Pentaho.\nDelivered mission-critical marketing and Voice/SMS gateway systems for Fortune 500 clients, utilizing Python, Vertica, and Pentaho.\nRescued and delivered a voice/SMS gateway system for the nationâ€™s largest bank after inheriting a year-long stalled project, preserving $10M+ annual client relationship and preventing potential contract termination of other services. Designed and implemented recommendation engines for major pharmaceutical companies, optimizing drug treatment awareness by 15% Modernized Kia Motorsâ€™ dealer optimization platform, migrating legacy VB.Net/PostgreSQL architecture to high-performance Java/Vertica solution, improving query response times by 80% Designed scalable ETL frameworks using Pentaho Data Integration, processing terabytes of marketing data and reducing data pipeline failures by 60% Mentored 15+ developers in advanced ETL techniques and data processing methodologies Contributed to talent acquisition strategy, interviewing and recommending candidates that strengthened technical capabilities across multiple client engagement teams 10/2011 â€“ 12/2012\nSenior ETL Architect Productive Data Solutions: Denver, CO Provided strategic guidance and expert knowledge that implemented ETL solutions for multiple states to power their healthcare exchanges.\nDesigned and implemented a hybrid ETL architecture combining Pentaho Data Integration with Python automation, processing millions of records daily and reducing data processing errors by 40% Drastically improved deployment processes by architecting a file-based Pentaho repository system with Subversion integration, achieving 99% deployment time reduction (from 60+ minutes to 30 seconds) Developed a HIPAA-compliant healthcare reporting system using Python, ensuring zero privacy violations while enabling real-time analytics for patient records Enhanced development team productivity by 50% through Agile methodology optimization, collaborating with business analysts to refine user story definitions and sprint planning processes Established automated testing framework using Linux shell scripting, mentoring QA teams on DevOps practices that reduced manual testing efforts by 70% Led technical training initiatives for development teams on advanced Python ETL techniques, improving code quality and standardizing best practices across projects Contributed to strategic hiring decisions through technical interviewing of SQL developers, ensuring team capability alignment with client needs Delivered solutions for complex data integration challenges across healthcare, financial services, and retail verticals under tight regulatory constraints Led the design and implementation of effective ETL systems for clients, providing strategic guidance and expert knowledge. 3/2006 â€“ 10/2011\nSoftware Architect Transzap: Denver, CO Drove enterprise software architecture transformation at high-growth oil and gas fintech startup, delivering scalable e-payables solutions that contributed to the companyâ€™s recognition in Deloitte Fast 500 and supported millions in transaction processing volume.\nPioneered adoption of Python-based automation framework, reducing manual data processing time by 80% and establishing foundation for scalable ETL operations across enterprise systems Architected and executed critical legacy system migration from Orion to Tomcat application server, ensuring zero-downtime transition for customer-facing e-payables platform serving thousands of active users Introduced cutting-edge columnar database technology (Vertica) to the enterprise stack, offloading analytical workloads from transactional systems and improving query performance by 90% Led SSAS cube modernization initiative, migrating complex MDX-based analytics to SQL-accessible Vertica platform, democratizing data access for business analysts Built a comprehensive ETL infrastructure using Pentaho Data Integration, processing financial transactions daily while maintaining 99.9% data accuracy Engineered SQL Server Integration Services pipelines for enterprise data warehouse, enabling real-time business intelligence for executive decision-making Optimized mission-critical C# application (Spendworks) startup performance, achieving a 95% reduction in load times (from minutes to seconds), dramatically improving user adoption rates Designed scalable system architecture supporting the companyâ€™s rapid growth trajectory, handling increases in transaction volume without performance degradation Mentored development team on emerging technologies and architectural best practices, establishing technical standards that supported company scaling from startup to enterprise 7/2000 â€“ 3/2006\nApplication Architect Calpine: Fort Collins, CO Led enterprise architecture at Fortune 500 energy company, pioneering real-time power plant analytics and telemetry systems that optimized operations across a fleet of natural gas facilities while driving company recognition as InformationWeek Top 100 Innovator.\nSpearheaded architectural oversight for $10M+ portfolio of mission-critical development projects, ensuring technical excellence across enterprise systems Pioneered early adoption of Microsoft .NET technologies at enterprise scale, collaborating directly with Microsoft development teams on C# language evolution and establishing Calpine as an industry technology leader Directly contributed technical innovations that earned Calpine a 5th place ranking in InformationWeek Top 100 Innovators (2005), positioning the company as an energy sector technology pioneer Managed project budgets up to $600K and established PMO standards for timeline management, delivering 95% of projects on time and under budget across the IT portfolio Architected a comprehensive business intelligence platform using ASP.NET, SQL Server, and SSAS, enabling real-time analysis of natural gas and electric power sales data Built an enterprise data warehouse integrating Maximo inventory systems using SQL Server, C#, and DTS, automating critical operational reporting and reducing manual processes by 80% Developed custom data mapping platform using C#, ADO.NET, Oracle, and OSI PI, standardizing data integration across heterogeneous industrial control systems Enhanced custom OLAP caching server, optimizing performance for complex energy market calculations (gas days, peaking periods, off-peak analysis) with sub-second response times Enhanced legacy C++/MFC libraries to support dynamic contract period management, improving operational flexibility for diverse power purchase agreements 12/1999 â€“ 7/2000\nSystems Analyst II City of Thornton: Thornton, CO Led municipal technology modernization initiatives for a growing suburban city, implementing mission-critical systems serving 77K+ residents while establishing software development best practices and mentoring technical staff on emerging enterprise technologies.\nArchitected and implemented a comprehensive software development lifecycle (SDLC) framework for municipal IT projects, reducing project delivery times by 30% and establishing quality standards across city departments Provided technical leadership and mentorship to MIS staff on advanced programming technologies, including C++, COM, MTS, and ASP, elevating team capabilities in enterprise application development Led strategic technology procurement processes, evaluating and recommending software solutions for critical municipal operations, including public safety, utilities, and citizen services systems Modernized legacy municipal systems serving police, fire, utilities, and administrative departments, ensuring 99.9% uptime for citizen-facing services and emergency response systems Spearheaded technical hiring initiatives, conducting candidate evaluations and building development team capabilities to support the cityâ€™s rapid growth and technology advancement needs Collaborated with department heads to align technology solutions with operational requirements, ensuring seamless integration across police dispatch, utilities management, and citizen services platforms Created technical documentation, creating a sustainable IT operations framework for the City of Thornton 1/1999 â€“ 12/1999\nInformation Technology Lead VantagePoint Network: Fort Collins, CO Led software engineering that pioneered the development of a groundbreaking precision agriculture platform, creating one of the industryâ€™s first web-based agricultural technology solutions that enabled crop professionals to optimize yields while reducing environmental impact across thousands of farming operations.\nArchitected revolutionary GPS-based yield mapping system using C++, ATL COM, ADO, MTS, MSMQ, and Oracle technologies, enabling real-time precision agriculture data collection that improved crop yields by 15-20% for early adopters Designed a comprehensive soil analysis and management platform integrating C++ ATL COM objects with enterprise Oracle databases, providing farmers with data-driven insights for optimized fertilizer application and soil health monitoring Built an advanced geospatial data migration engine using ESRI SDE APIs and C++, enabling seamless integration of precision agriculture data across heterogeneous farming systems and GIS platforms Created a web-based crop record management system using ASP and Oracle, digitizing paper-based processes and reducing administrative overhead by 60% for agricultural operations Led quality assurance standardization initiative, collaborating with QA teams to establish bug tracking, testing protocols, and code quality standards that reduced production defects by 40% Partnered with database architects to design a scalable agricultural data warehouse supporting complex crop rotation analysis, field mapping, and yield prediction algorithms Facilitated code review processes and mentored development team on emerging web technologies, establishing engineering best practices that supported the companyâ€™s rapid growth in the AgTech market Contributed to technical innovations that positioned VantagePoint as an early leader in the precision agriculture technology sector 2/1995 â€“ 1/1999\nProgrammer/Analyst State Farm Insurance Companies: Bloomington, IL Delivered enterprise-scale insurance technology solutions for a Fortune 50 company, architecting mission-critical systems that processed millions of policies annually while mentoring development teams and establishing coding standards across business units.\nArchitected a comprehensive COM-based integration framework connecting third-party insurance software with State Farmâ€™s mainframe legacy systems, enabling seamless data flow across enterprise applications serving 80M+ policyholders Built pioneering intranet-based policy rating application using COM, COM TI, DB2, DHTML, and MTS technologies, reducing policy quote generation time from hours to minutes and improving agent productivity by 40% Led after-hours technical training initiatives in C++ programming, developing internal expertise Designed high-performance data replication system using C++, DB2, and MQ Series, synchronizing marketing data across 5,000+ agent locations nationwide with 99.9% reliability Provided critical vendor support in debugging a complex MFC C++ life insurance illustration application, ensuring accurate actuarial calculations for a multi-billion dollar life insurance portfolio Enhanced AionDS-based expert system for auto policy pricing, implementing advanced business rules that improved pricing accuracy by 25% and reduced underwriting exceptions Optimized legacy COBOL applications supporting core insurance operations, achieving 60% performance improvements through systematic tuning and debugging initiatives Collaborated with business analysts to translate complex insurance regulations into automated business rules, enabling consistent policy management across all product lines Contributed to digital transformation initiatives that positioned State Farm as a technology leader in the insurance industry during the early web adoption period 1/1996 - 12/1996\nC++ Instructor Heartland Community College: Bloomington, IL Delivered comprehensive object-oriented programming education to 50+ students while maintaining a full-time State Farm position, developing curriculum and teaching methodologies that achieved a 95% student success rate in C++ programming concepts.\nDesigned and delivered a comprehensive C++ curriculum covering advanced object-oriented programming principles, data structures, and software engineering best practices for computer science and engineering students Taught complex programming concepts, including inheritance, polymorphism, exception handling, and operator overloading, to a diverse student population with varying technical backgrounds Developed hands-on laboratory exercises and real-world programming projects that improved student comprehension by 40% compared to traditional lecture-only approaches Mentored students in software design principles, debugging techniques, and industry-standard coding practices, preparing them for internships and entry-level development positions Created teaching materials and practical assignments that bridged academic concepts with industry applications, drawing from my development experience Collaborated with computer science department faculty to align curriculum with industry needs and emerging programming trends Maintained 95% student retention rate through engaging instruction methods and individualized support for struggling learners Applied State Farm enterprise development experience to provide students with practical insights into the commercial software development lifecycle 5/1993 â€“ 1/1995\nComputer Operator Rockwell Automation Allen â€“ Bradley: Mequon, WI Operated mission-critical mainframe systems for Fortune 500 industrial automation leader while contributing to successful ISO 9000 certification initiatives.\nOperated and maintained enterprise mainframe systems processing critical manufacturing data for Rockwellâ€™s worldwide industrial automation operations, supporting $2B+ annual revenue Developed advanced JCL and REXX automation scripts that reduced manual backup processes by 75% and eliminated human error in critical data protection workflows Led automation initiative for mainframe application scheduling, designing workflows that increased operational efficiency and reduced after-hours support requirements Supported multiple successful ISO 9000 quality certification audits through meticulous documentation of mainframe operational procedures, ensuring compliance with international manufacturing standards Collaborated with systems analysts and programmers on troubleshooting complex system issues Demonstrated exceptional attention to detail in system documentation and change management Provided technical support during system upgrades and maintenance windows, coordinating with engineering teams to minimize production disruption Built foundational expertise in enterprise system operations and quality management that supported transition into a software engineering career Education University of Wisconsin - Milwaukee\nBachelor of Business Administration (Completed in December 1994)\nMajor: Management Information Systems\n","wordCount":"2731","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://kurtfehlhauer.com/about/"},"publisher":{"@type":"Organization","name":"Kurt Fehlhauer","logo":{"@type":"ImageObject","url":"https://kurtfehlhauer.com/favicon.ico"}}}</script></head><body class=dark id=top><header class=header><nav class=nav><div class=logo><a href=https://kurtfehlhauer.com/ accesskey=h title="Kurt Fehlhauer (Alt + H)">Kurt Fehlhauer</a><div class=logo-switches></div></div><ul id=menu><li><a href=https://kurtfehlhauer.com/photography/ title=Photography><span>Photography</span></a></li><li><a href=https://kurtfehlhauer.com/posts/ title=posts><span>posts</span></a></li><li><a href=https://kurtfehlhauer.com/about/ title=About><span class=active>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://kurtfehlhauer.com/>Home</a></div><h1 class="post-title entry-hint-parent"></h1><div class=post-meta></div></header><div class=post-content><h1 id=resumecv>Resume/CV<a hidden class=anchor aria-hidden=true href=#resumecv>#</a></h1><p>Kurt Fehlhauer<br>email: <a href=mailto:kfehlhauer@pm.me>kfehlhauer@pm.me</a></p><h2 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h2><p>I specialize in leading large-scale data engineering initiatives and driving enterprise-wide data architecture transformations. My efforts have enabled scalable multi-petabyte platforms that support artificial intelligence applications and data-driven decision-making across global operations. I am passionate about enabling AI usage within the teams I manage to accelerate the delivery of solutions.</p><p>My expertise includes designing and deploying robust data platforms using technologies such as Databricks Spark, Kubernetes, and Delta Lake, while advancing cost-efficient solutions, including Rust-based query engines. Committed to fostering innovation, I build global teams that deliver and empower analytics at scale.</p><p>I continually strive to expand my skill set. Currently, I am experimenting with Rust on the Solana blockchain and building WASM-powered sites using Dioxus.</p><h2 id=experience>Experience<a hidden class=anchor aria-hidden=true href=#experience>#</a></h2><p>2/2022 - Present</p><h3 id=chief-data-architect>Chief Data Architect<a hidden class=anchor aria-hidden=true href=#chief-data-architect>#</a></h3><h4 id=stellantis-remote>Stellantis: Remote<a hidden class=anchor aria-hidden=true href=#stellantis-remote>#</a></h4><p>Spearheaded department-wide data architecture transformation at Stellantis, delivering scalable multi-petabyte platforms that enable AI initiatives and data-driven decision making across global operations.</p><ul><li>Built and led a global data engineering organization spanning multiple continents, establishing DevOps practices that reduced system delivery time by 40%</li><li>Architected and deployed a multi-petabyte data platform using Databricks Spark, Kubernetes, and Delta Lake, supporting 500+ employees with enterprise-scale analytics</li><li>Pioneered implementation of Rust-based query engines (DataFusion, delta-rs) to reduce query costs by 80% for data quality time series data.</li><li>Successfully consolidated disparate data systems from the FCA LLC and PSA Group merger, eliminating redundancies and reducing operational costs by $2M annually</li><li>Designed and implemented petabyte-scale vehicle data collection architecture for both research and production fleets, enabling real-time analytics and predictive maintenance</li><li>Led cross-functional collaboration with AI teams to productionize large language models (LLMs), accelerating time-to-market for AI-powered features</li><li>Established comprehensive data governance framework and PII handling protocols, ensuring regulatory compliance across multiple regions</li><li>Forecast yearly multimillion-dollar data platform budget</li><li>Currently serving as Acting Head of Data Governance (March 2025), focusing on data discovery, AI enablement, and data democratization initiatives</li><li>Developed portable cloud-agnostic architectures, ensuring business continuity in regions with limited cloud vendor availability</li></ul><hr><p>5/2019 â€“ 2/2022</p><h3 id=senior-manager-etl>Senior Manager, ETL<a hidden class=anchor aria-hidden=true href=#senior-manager-etl>#</a></h3><h4 id=activision-publishing-remote>Activision Publishing: Remote<a hidden class=anchor aria-hidden=true href=#activision-publishing-remote>#</a></h4><p>Led a data engineering team supporting the Call of Duty franchise and game studio analytics, driving platform modernization initiatives that reduced data processing times by 50% while ensuring regulatory compliance across global markets.</p><ul><li>Managed the analytical data pipeline architecture for the Call of Duty franchise, processing petabytes of player behavioral data and game telemetry to support 100M+ active users</li><li>Orchestrated successful cloud migration from AWS to Google Cloud Platform, reducing infrastructure costs by 30% and improving cross-platform compatibility for development teams</li><li>Spearheaded legacy ETL system modernization, normalizing data across multiple Call of Duty titles and achieving a 50% reduction in data availability latency</li><li>Implemented Astronomer Airflow deployment, standardizing workflow orchestration and reducing deployment complexity</li><li>Consolidated fragmented big data ecosystem (Qubole, Hive, Presto, Redshift) into unified Databricks platform, eliminating vendor sprawl and reducing operational overhead by 40%</li><li>Championed MLFlow adoption across the data science organization, establishing standardized ML lifecycle management for 50+ data scientists</li><li>Engineered a high-performance third-party data ingestion framework using functional programming paradigms (Cats/ZIO, Circe, http4s) on Kubernetes, enabling real-time integration of external market data</li><li>Established a comprehensive data privacy and compliance framework implementing GDPR and CCPA industry regulations, ensuring zero compliance violations across global data operations</li><li>Built scalable data transformation pipelines converting proprietary game artifacts into Spark SQL-queryable formats, democratizing data access for 200+ analysts and stakeholders</li><li>Mentored 20+ engineers in modern data stack technologies (Airflow, Kubernetes, Scala, Spark).</li><li>Managed $5M+ annual vendor contracts and platform investments, optimizing cost-per-query metrics and ensuring 99.9% platform availability</li></ul><hr><p>6/2014 â€“ 4/2019</p><h3 id=lead-database-architect>Lead Database Architect<a hidden class=anchor aria-hidden=true href=#lead-database-architect>#</a></h3><h4 id=activision-publishing-boulder-coremote>Activision Publishing: Boulder, CO/Remote<a hidden class=anchor aria-hidden=true href=#activision-publishing-boulder-coremote>#</a></h4><p>Pioneered game analytics data architecture at Activision, establishing foundational analytics infrastructure that supported billion-dollar gaming franchises and enabled data-driven game design decisions across global development studios.</p><ul><li>Architected and managed a comprehensive data ecosystem for the Call of Duty franchise, processing petabytes of player telemetry and game performance data supporting 300M+ registered users</li><li>Led groundbreaking company-wide adoption of Apache Spark and Airflow, establishing Activision as an early adopter of modern big data technologies and reducing processing times by 60%</li><li>Designed and implemented a self-service Spark-based ETL framework adopted across Call of Duty mainline and Call of Duty Mobile, democratizing data access for 30+ analysts</li><li>Spearheaded platform consolidation initiative, migrating from fragmented Qubole/Hive/Presto ecosystem to unified Databricks Delta Lake architecture, reducing operational complexity by 80%</li><li>Established Activision&rsquo;s first MLFlow implementation for data science workflows, standardizing machine learning lifecycle management across 20+ data scientists and accelerating model deployment by 40%</li><li>Built custom Spark extensions and UDFs that enhanced analytical capabilities, simplifying otherwise complex and redundant SQL</li><li>Transformed proprietary game artifact data into Spark SQL-compatible formats, enabling cross-studio analytics and reducing time-to-insight for game developers by 70%</li><li>Modernized legacy studio data tools to integrate with enterprise big data frameworks, eliminating data silos and improving development team productivity</li><li>Mentored cross-functional teams on big data best practices, creating technical standards that accelerated analytical insight delivery by 60%</li></ul><hr><p>1/2013 â€“ 6/2014</p><h3 id=senior-consultant>Senior Consultant<a hidden class=anchor aria-hidden=true href=#senior-consultant>#</a></h3><h4 id=fico-remote>FICO: Remote<a hidden class=anchor aria-hidden=true href=#fico-remote>#</a></h4><p>Enhanced credit and retail applications for diverse financial institutions and implemented recommendation systems for major pharmaceutical companies, utilizing Python, Vertica, and Pentaho.</p><p>Delivered mission-critical marketing and Voice/SMS gateway systems for Fortune 500 clients, utilizing Python, Vertica, and Pentaho.</p><ul><li>Rescued and delivered a voice/SMS gateway system for the nation&rsquo;s largest bank after inheriting a year-long stalled project, preserving $10M+ annual client relationship and preventing potential contract termination of other services.</li><li>Designed and implemented recommendation engines for major pharmaceutical companies, optimizing drug treatment awareness by 15%</li><li>Modernized Kia Motors&rsquo; dealer optimization platform, migrating legacy VB.Net/PostgreSQL architecture to high-performance Java/Vertica solution, improving query response times by 80%</li><li>Designed scalable ETL frameworks using Pentaho Data Integration, processing terabytes of marketing data and reducing data pipeline failures by 60%</li><li>Mentored 15+ developers in advanced ETL techniques and data processing methodologies</li><li>Contributed to talent acquisition strategy, interviewing and recommending candidates that strengthened technical capabilities across multiple client engagement teams</li></ul><hr><p>10/2011 â€“ 12/2012</p><h3 id=senior-etl-architect>Senior ETL Architect<a hidden class=anchor aria-hidden=true href=#senior-etl-architect>#</a></h3><h4 id=productive-data-solutions-denver-co>Productive Data Solutions: Denver, CO<a hidden class=anchor aria-hidden=true href=#productive-data-solutions-denver-co>#</a></h4><p>Provided strategic guidance and expert knowledge that implemented ETL solutions for multiple states to power their healthcare exchanges.</p><ul><li>Designed and implemented a hybrid ETL architecture combining Pentaho Data Integration with Python automation, processing millions of records daily and reducing data processing errors by 40%</li><li>Drastically improved deployment processes by architecting a file-based Pentaho repository system with Subversion integration, achieving 99% deployment time reduction (from 60+ minutes to 30 seconds)</li><li>Developed a HIPAA-compliant healthcare reporting system using Python, ensuring zero privacy violations while enabling real-time analytics for patient records</li><li>Enhanced development team productivity by 50% through Agile methodology optimization, collaborating with business analysts to refine user story definitions and sprint planning processes</li><li>Established automated testing framework using Linux shell scripting, mentoring QA teams on DevOps practices that reduced manual testing efforts by 70%</li><li>Led technical training initiatives for development teams on advanced Python ETL techniques, improving code quality and standardizing best practices across projects</li><li>Contributed to strategic hiring decisions through technical interviewing of SQL developers, ensuring team capability alignment with client needs</li><li>Delivered solutions for complex data integration challenges across healthcare, financial services, and retail verticals under tight regulatory constraints
Led the design and implementation of effective ETL systems for clients, providing strategic guidance and expert knowledge.</li></ul><hr><p>3/2006 â€“ 10/2011</p><h3 id=software-architect>Software Architect<a hidden class=anchor aria-hidden=true href=#software-architect>#</a></h3><h4 id=transzap-denver-co>Transzap: Denver, CO<a hidden class=anchor aria-hidden=true href=#transzap-denver-co>#</a></h4><p>Drove enterprise software architecture transformation at high-growth oil and gas fintech startup, delivering scalable e-payables solutions that contributed to the company&rsquo;s recognition in Deloitte Fast 500 and supported millions in transaction processing volume.</p><ul><li>Pioneered adoption of Python-based automation framework, reducing manual data processing time by 80% and establishing foundation for scalable ETL operations across enterprise systems</li><li>Architected and executed critical legacy system migration from Orion to Tomcat application server, ensuring zero-downtime transition for customer-facing e-payables platform serving thousands of active users</li><li>Introduced cutting-edge columnar database technology (Vertica) to the enterprise stack, offloading analytical workloads from transactional systems and improving query performance by 90%</li><li>Led SSAS cube modernization initiative, migrating complex MDX-based analytics to SQL-accessible Vertica platform, democratizing data access for business analysts</li><li>Built a comprehensive ETL infrastructure using Pentaho Data Integration, processing financial transactions daily while maintaining 99.9% data accuracy</li><li>Engineered SQL Server Integration Services pipelines for enterprise data warehouse, enabling real-time business intelligence for executive decision-making</li><li>Optimized mission-critical C# application (Spendworks) startup performance, achieving a 95% reduction in load times (from minutes to seconds), dramatically improving user adoption rates</li><li>Designed scalable system architecture supporting the company&rsquo;s rapid growth trajectory, handling increases in transaction volume without performance degradation</li><li>Mentored development team on emerging technologies and architectural best practices, establishing technical standards that supported company scaling from startup to enterprise</li></ul><hr><p>7/2000 â€“ 3/2006</p><h3 id=application-architect>Application Architect<a hidden class=anchor aria-hidden=true href=#application-architect>#</a></h3><h4 id=calpine-fort-collins-co>Calpine: Fort Collins, CO<a hidden class=anchor aria-hidden=true href=#calpine-fort-collins-co>#</a></h4><p>Led enterprise architecture at Fortune 500 energy company, pioneering real-time power plant analytics and telemetry systems that optimized operations across a fleet of natural gas facilities while driving company recognition as InformationWeek Top 100 Innovator.</p><ul><li>Spearheaded architectural oversight for $10M+ portfolio of mission-critical development projects, ensuring technical excellence across enterprise systems</li><li>Pioneered early adoption of Microsoft .NET technologies at enterprise scale, collaborating directly with Microsoft development teams on C# language evolution and establishing Calpine as an industry technology leader</li><li>Directly contributed technical innovations that earned Calpine a 5th place ranking in InformationWeek Top 100 Innovators (2005), positioning the company as an energy sector technology pioneer</li><li>Managed project budgets up to $600K and established PMO standards for timeline management, delivering 95% of projects on time and under budget across the IT portfolio</li><li>Architected a comprehensive business intelligence platform using ASP.NET, SQL Server, and SSAS, enabling real-time analysis of natural gas and electric power sales data</li><li>Built an enterprise data warehouse integrating Maximo inventory systems using SQL Server, C#, and DTS, automating critical operational reporting and reducing manual processes by 80%</li><li>Developed custom data mapping platform using C#, ADO.NET, Oracle, and OSI PI, standardizing data integration across heterogeneous industrial control systems</li><li>Enhanced custom OLAP caching server, optimizing performance for complex energy market calculations (gas days, peaking periods, off-peak analysis) with sub-second response times</li><li>Enhanced legacy C++/MFC libraries to support dynamic contract period management, improving operational flexibility for diverse power purchase agreements</li></ul><hr><p>12/1999 â€“ 7/2000</p><h3 id=systems-analyst-ii>Systems Analyst II<a hidden class=anchor aria-hidden=true href=#systems-analyst-ii>#</a></h3><h4 id=city-of-thornton-thornton-co>City of Thornton: Thornton, CO<a hidden class=anchor aria-hidden=true href=#city-of-thornton-thornton-co>#</a></h4><p>Led municipal technology modernization initiatives for a growing suburban city, implementing mission-critical systems serving 77K+ residents while establishing software development best practices and mentoring technical staff on emerging enterprise technologies.</p><ul><li>Architected and implemented a comprehensive software development lifecycle (SDLC) framework for municipal IT projects, reducing project delivery times by 30% and establishing quality standards across city departments</li><li>Provided technical leadership and mentorship to MIS staff on advanced programming technologies, including C++, COM, MTS, and ASP, elevating team capabilities in enterprise application development</li><li>Led strategic technology procurement processes, evaluating and recommending software solutions for critical municipal operations, including public safety, utilities, and citizen services systems</li><li>Modernized legacy municipal systems serving police, fire, utilities, and administrative departments, ensuring 99.9% uptime for citizen-facing services and emergency response systems</li><li>Spearheaded technical hiring initiatives, conducting candidate evaluations and building development team capabilities to support the city&rsquo;s rapid growth and technology advancement needs</li><li>Collaborated with department heads to align technology solutions with operational requirements, ensuring seamless integration across police dispatch, utilities management, and citizen services platforms</li><li>Created technical documentation, creating a sustainable IT operations framework for the City of Thornton</li></ul><hr><p>1/1999 â€“ 12/1999</p><h3 id=information-technology-lead>Information Technology Lead<a hidden class=anchor aria-hidden=true href=#information-technology-lead>#</a></h3><h4 id=vantagepoint-network-fort-collins-co>VantagePoint Network: Fort Collins, CO<a hidden class=anchor aria-hidden=true href=#vantagepoint-network-fort-collins-co>#</a></h4><p>Led software engineering that pioneered the development of a groundbreaking precision agriculture platform, creating one of the industry&rsquo;s first web-based agricultural technology solutions that enabled crop professionals to optimize yields while reducing environmental impact across thousands of farming operations.</p><ul><li>Architected revolutionary GPS-based yield mapping system using C++, ATL COM, ADO, MTS, MSMQ, and Oracle technologies, enabling real-time precision agriculture data collection that improved crop yields by 15-20% for early adopters</li><li>Designed a comprehensive soil analysis and management platform integrating C++ ATL COM objects with enterprise Oracle databases, providing farmers with data-driven insights for optimized fertilizer application and soil health monitoring</li><li>Built an advanced geospatial data migration engine using ESRI SDE APIs and C++, enabling seamless integration of precision agriculture data across heterogeneous farming systems and GIS platforms</li><li>Created a web-based crop record management system using ASP and Oracle, digitizing paper-based processes and reducing administrative overhead by 60% for agricultural operations</li><li>Led quality assurance standardization initiative, collaborating with QA teams to establish bug tracking, testing protocols, and code quality standards that reduced production defects by 40%</li><li>Partnered with database architects to design a scalable agricultural data warehouse supporting complex crop rotation analysis, field mapping, and yield prediction algorithms</li><li>Facilitated code review processes and mentored development team on emerging web technologies, establishing engineering best practices that supported the company&rsquo;s rapid growth in the AgTech market</li><li>Contributed to technical innovations that positioned VantagePoint as an early leader in the precision agriculture technology sector</li></ul><hr><p>2/1995 â€“ 1/1999</p><h3 id=programmeranalyst>Programmer/Analyst<a hidden class=anchor aria-hidden=true href=#programmeranalyst>#</a></h3><h4 id=state-farm-insurance-companies-bloomington-il>State Farm Insurance Companies: Bloomington, IL<a hidden class=anchor aria-hidden=true href=#state-farm-insurance-companies-bloomington-il>#</a></h4><p>Delivered enterprise-scale insurance technology solutions for a Fortune 50 company, architecting mission-critical systems that processed millions of policies annually while mentoring development teams and establishing coding standards across business units.</p><ul><li>Architected a comprehensive COM-based integration framework connecting third-party insurance software with State Farm&rsquo;s mainframe legacy systems, enabling seamless data flow across enterprise applications serving 80M+ policyholders</li><li>Built pioneering intranet-based policy rating application using COM, COM TI, DB2, DHTML, and MTS technologies, reducing policy quote generation time from hours to minutes and improving agent productivity by 40%</li><li>Led after-hours technical training initiatives in C++ programming, developing internal expertise</li><li>Designed high-performance data replication system using C++, DB2, and MQ Series, synchronizing marketing data across 5,000+ agent locations nationwide with 99.9% reliability</li><li>Provided critical vendor support in debugging a complex MFC C++ life insurance illustration application, ensuring accurate actuarial calculations for a multi-billion dollar life insurance portfolio</li><li>Enhanced AionDS-based expert system for auto policy pricing, implementing advanced business rules that improved pricing accuracy by 25% and reduced underwriting exceptions</li><li>Optimized legacy COBOL applications supporting core insurance operations, achieving 60% performance improvements through systematic tuning and debugging initiatives</li><li>Collaborated with business analysts to translate complex insurance regulations into automated business rules, enabling consistent policy management across all product lines</li><li>Contributed to digital transformation initiatives that positioned State Farm as a technology leader in the insurance industry during the early web adoption period</li></ul><hr><p>1/1996 - 12/1996</p><h3 id=c-instructor>C++ Instructor<a hidden class=anchor aria-hidden=true href=#c-instructor>#</a></h3><h4 id=heartland-community-college-bloomington-il>Heartland Community College: Bloomington, IL<a hidden class=anchor aria-hidden=true href=#heartland-community-college-bloomington-il>#</a></h4><p>Delivered comprehensive object-oriented programming education to 50+ students while maintaining a full-time State Farm position, developing curriculum and teaching methodologies that achieved a 95% student success rate in C++ programming concepts.</p><ul><li>Designed and delivered a comprehensive C++ curriculum covering advanced object-oriented programming principles, data structures, and software engineering best practices for computer science and engineering students</li><li>Taught complex programming concepts, including inheritance, polymorphism, exception handling, and operator overloading, to a diverse student population with varying technical backgrounds</li><li>Developed hands-on laboratory exercises and real-world programming projects that improved student comprehension by 40% compared to traditional lecture-only approaches</li><li>Mentored students in software design principles, debugging techniques, and industry-standard coding practices, preparing them for internships and entry-level development positions</li><li>Created teaching materials and practical assignments that bridged academic concepts with industry applications, drawing from my development experience</li><li>Collaborated with computer science department faculty to align curriculum with industry needs and emerging programming trends</li><li>Maintained 95% student retention rate through engaging instruction methods and individualized support for struggling learners</li><li>Applied State Farm enterprise development experience to provide students with practical insights into the commercial software development lifecycle</li></ul><hr><p>5/1993 â€“ 1/1995</p><h3 id=computer-operator>Computer Operator<a hidden class=anchor aria-hidden=true href=#computer-operator>#</a></h3><h4 id=rockwell-automation-allen--bradley-mequon-wi>Rockwell Automation Allen â€“ Bradley: Mequon, WI<a hidden class=anchor aria-hidden=true href=#rockwell-automation-allen--bradley-mequon-wi>#</a></h4><p>Operated mission-critical mainframe systems for Fortune 500 industrial automation leader while contributing to successful ISO 9000 certification initiatives.</p><ul><li>Operated and maintained enterprise mainframe systems processing critical manufacturing data for Rockwell&rsquo;s worldwide industrial automation operations, supporting $2B+ annual revenue</li><li>Developed advanced JCL and REXX automation scripts that reduced manual backup processes by 75% and eliminated human error in critical data protection workflows</li><li>Led automation initiative for mainframe application scheduling, designing workflows that increased operational efficiency and reduced after-hours support requirements</li><li>Supported multiple successful ISO 9000 quality certification audits through meticulous documentation of mainframe operational procedures, ensuring compliance with international manufacturing standards</li><li>Collaborated with systems analysts and programmers on troubleshooting complex system issues</li><li>Demonstrated exceptional attention to detail in system documentation and change management</li><li>Provided technical support during system upgrades and maintenance windows, coordinating with engineering teams to minimize production disruption</li><li>Built foundational expertise in enterprise system operations and quality management that supported transition into a software engineering career</li></ul><h2 id=education>Education<a hidden class=anchor aria-hidden=true href=#education>#</a></h2><p>University of Wisconsin - Milwaukee<br>Bachelor of Business Administration (Completed in December 1994)<br>Major: Management Information Systems</p></div><footer class=post-footer><ul class=post-tags></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share  on x" href="https://x.com/intent/tweet/?text=&amp;url=https%3a%2f%2fkurtfehlhauer.com%2fabout%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share  on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fkurtfehlhauer.com%2fabout%2f&amp;title=&amp;summary=&amp;source=https%3a%2f%2fkurtfehlhauer.com%2fabout%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share  on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fkurtfehlhauer.com%2fabout%2f&title="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share  on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fkurtfehlhauer.com%2fabout%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share  on whatsapp" href="https://api.whatsapp.com/send?text=%20-%20https%3a%2f%2fkurtfehlhauer.com%2fabout%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share  on telegram" href="https://telegram.me/share/url?text=&amp;url=https%3a%2f%2fkurtfehlhauer.com%2fabout%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share  on ycombinator" href="https://news.ycombinator.com/submitlink?t=&u=https%3a%2f%2fkurtfehlhauer.com%2fabout%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://kurtfehlhauer.com/>Kurt Fehlhauer</a></span> Â·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>